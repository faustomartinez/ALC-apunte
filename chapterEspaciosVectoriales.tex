\chapter{Nociones básicas de álgebra lineal}

\section{Vectores y matrices}

\subsection{Vectores}
Para $n \in \N$, definimos un vector de $n$ coordenadas como una sucesión de $n$ n\'umeros reales o complejos $\vb = (v_1, \dots, v_n)$.
Denotamos $\R^n$ al conjunto de todos los vectores reales de $n$ coordenadas y $\C^n$ al conjunto de todos los vectores complejos de $n$ coordenadas.
Ya que la mayoría de los resultados que veremos valen tanto en $\R$ como en $\C$, los enunciamos usando la letra $\K$. En los casos en que debamos restringirnos a $\R$ o $\C$ lo señalaremos explícitamente. Solo haremos uso de  definiciones y propiedades elementales de los complejos, antes de continuar recordamos algunas de ellas que aparecerán más adelante
\begin{enumerate}
\item $i^2=-1$.
 \item Si $z=a+ib$ el conjugado se define como $\overline{z}=a-ib$.
 \item $\forall z,w\in \C$,  $\overline{zw}=\overline{z}\,\overline{w}$.
 \item El módulo de $z$, se define como $|z|=\sqrt{a^2+b^2}$ y representa la distancia del complejo $z$ al origen.
 \item $\forall z,w\in \C$, $|zw|=|z||w|$
 \item $|z|^2=z\overline{z}$, en particular se observa que si $z\neq 0$, $z\frac{\overline{z}}{|z|^2}=1$. Llamamos $z^{-1}=\frac{\overline{z}}{|z|^2}$.
 \item $\forall \theta\in \R$, se define $e^{i\theta}=\cos(\theta)+i\sen(\theta)$, en particular $|e^{i\theta}|=1$. Por otro lado, usando trigonometría elemental, se ve que si $|w|=1$, existe $\theta\in \R$ tal que $w=e^{i\theta}$.
 \item Ya que si $z\neq 0$ se tiene que $\left| \frac{z}{|z|}\right|=1$, del ítem previo se observa que si $z\neq 0$, puede escribirse $z=|z|e^{i\theta}$ con $\theta\in \R$.
 \item Todo polinomio a coeficientes en $\mathbb{C}$ de grado $n\ge 1$ tiene exactamente $n$ raíces -contadas con su multiplicidad- en $\C$ (resultado que suele llamarse Teorema Fundamental del Álgebra).
\end{enumerate}



\begin{ejemplo}\leavevmode
\begin{itemize}
\item   $\R^2$ es el plano coordenado.
\item   $\R^3$ es el espacio de 3 dimensiones.
\end{itemize}
\end{ejemplo}

\begin{ejemplo}\leavevmode
\begin{itemize}
\item $\vb = (1,2) \in \mathbb{R}^2$.
\item $\ub = (2, -1, \pi, 3/2) \in \mathbb{R}^4$.
\item $\wb = (1-2i,3e^{3i})\in \C^2 $.
\end{itemize}
\end{ejemplo}

En \python definimos vectores con el comando \texttt{array} (arreglo) del paquete \texttt{numpy}.

\begin{Shaded}
\begin{lstlisting}[language=python]
import numpy as np
v1 = np.array([10, 5, -7, 1])
print(v1)

v2 = np.array([5, 0, 3/2, 2])
print(v2)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% v1 =  [10  5 -7  1]
%% v2 =  [5.  0.  1.5 2. ]
\end{verbatim}

\subsection{Matrices}

Denotamos $\K^{m \times n}$ al espacio de matrices de números reales o complejos de $m$ filas y $n$ columnas, que podemos considerar como un vector de $m \times n$ coordenadas agrupadas en $m$ filas de $n$ coordenadas.

\begin{ejemplo}\leavevmode\noindent
\begin{enumerate}
\begin{minipage}{0.3\linewidth}
\item   $\begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{pmatrix} \in \mathbb{R}^{2 \times 3}$
\end{minipage}
\begin{minipage}{0.3\linewidth}
\item   $\begin{pmatrix} 1 \\ 7 \\ 0.6 \\ -1 \end{pmatrix} \in \mathbb{R}^{4 \times 1}$
\end{minipage}
\begin{minipage}{0.4\linewidth}
\item   $\begin{pmatrix} 1 & 5 + i \\ 7 -2i & 0 \\ i & 3 \end{pmatrix} \in \C^{3 \times 2}$
\end{minipage}
\end{enumerate}
\end{ejemplo}

Es común considerar a los vectores en $\K^n$ como matrices columna. Es decir, al vector $v=(1,2,3)$ lo pensamos como matriz $\begin{pmatrix} 1 \\ 2 \\ 3\end{pmatrix}$ cuando trabajamos con matrices.

En \python definimos matrices usando el mismo comando \texttt{array} que utilizamos para vectores, pero ingresando cada fila como un vector, es decir para \python una matriz es un arreglo de dos dimensiones, que se guarda como un arreglo de arreglos de dimensión 1.

\begin{Shaded}
\begin{lstlisting}[language=python]
A = np.array([[1,2],[3,4]]) # Matriz de 2 x 2
print("A = \n", A)

B = np.array([[1,2,3,4],[7,1,2,-1]]) # Matriz de 4 x 2
print("B = \n", B)

C = np.array([[1], [7], [1/3]]) # Matriz columna de 1 x 3
print("C = \n", C)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% A =
%%  [[1 2]
%%  [3 4]]
%% B =
%%  [[ 1  2  3  4]
%%  [ 7  1  2 -1]]
%% C =
%%  [[1.        ]
%%  [7.        ]
%%  [0.33333333]]
\end{verbatim}

Podemos acceder a las casillas de un vector o matriz usando los índices de las casillas,
teniendo en cuenta que en \python los índices se numeran siempre empezando en 0.

\begin{Shaded}
\begin{lstlisting}[language=python]
v1 = np.array([1,2,5,10])
print("v1[2] = ", v1[2])

A = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])
print("A[2,3] = ", A[2,3])
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% v1[2] = 5
%% A[2,3] = 12
\end{verbatim}

\subsection{Suma y producto por escalar}
Tanto en vectores como en matrices podemos realizar las siguientes operaciones, que como veremos m\'as adelante corresponden a operaciones de espacio vectorial:

\begin{itemize}
\item Suma de vectores o matrices del mismo tamaño coordenada a coordenada.
Si $\vb = (v_1, v_2, \dots, v_n)$ y $\ub = (u_1, u_2, \dots, u_n)$,
$$
\vb + \ub = (v_1 + u_1, v_2 + u_2, \dots, v_n + u_n).
$$

\item Producto de vectores o matrices por un escalar.
Si $a \in \R$ o $\C$ y $\vb = (v_1, v_2, \dots, v_n)$,
$$
a \vb = (av_1, av_2, \dots, av_n).
$$

\end{itemize}

En \python realizamos estas operaciones con los símbolos usuales $+$ y $*$.
\begin{Shaded}
\begin{lstlisting}[language=python]
import numpy as np
v1 = np.array([10, 5, -7, 1])
v2 = np.array([5, 0, 7, 2])
print("v1 + v2 = ", v1 + v2)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
## [15 5 0 3]
\end{verbatim}

\begin{Shaded}
\begin{lstlisting}[language=python]
A1 = np.array([[1,2],[3,4]])
print("A1 = \n", A1)

A2 = np.array([[2,7],[1,0]])
print("A2 = \n", A2)

A3 = np.array([[2,7,1,0]])
print("A3 = \n", A3)

print("A1 + A2 = \n", A1 + A2) # Matriz de 2 x 2

# No podemos sumar matrices de distinto tamaño
#print("A1 + A3 = \n", A1 + A3)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
## A1 =
## [[1 2]
## [3 4]]
## A2 =
## [[2 7]
## [1 0]]
## A3 =
## [2 7 1 0]
## A1 + A2 =
## [[3 9]
## [4 4]]
## [15 5 0 3]
\end{verbatim}

\section{Sistemas lineales de ecuaciones}

\subsection{Resolución de sistemas de ecuaciones por triangulación (eliminación gaussiana)}

La eliminación gaussiana es un método muy eficiente para resolver sistemas de ecuaciones lineales en forma directa (es decir, sin utilizar métodos iterativos que aproximan la solución).

A modo de ejemplo, resolvemos el siguiente sistema de ecuaciones.

$$
\left\{ {\begin{alignedat}{7}
x&&\;+\;&&5y&&\;+\;&&5z&&\;=\;&&2&\\
2x&&\;+\;&&2y&&\;-\;&&3z&&\;=\;&&-1&\\
-x&&\;-\;&&9y&&\;+\;&&2z&&=\;&&9&.
\end{alignedat}} \right.
$$

A partir del sistema, construimos la \textbf{matriz ampliada} de coeficientes y términos independientes:
$$
\left(
\begin{array}{rrr|r}1&5&5&2\\2&2&-3&-1\\-1&-9&2&9\end{array}
\right).
$$

Triangulamos la matriz realizando operaciones de filas. Las operaciones permitidas (que no afectan las soluciones del sistema) son:
\begin{itemize}
\item  sumarle o restarle a una fila un múltiplo de otra fila,
\item  intercambiar dos filas entre si.
\item  multiplicar una fila por un escalar distinto de 0.
\end{itemize}

El algoritmo de eliminación gaussiana consiste en triangular o escalonar la matriz obteniendo 0's abajo de los elementos de la diagonal, o más generalmente, produciendo que en cada fila la cantidad de 0's iniciales sea mayor que en la fila anterior.

Realizamos las siguientes operaciones:

\begin{align*}
\left(
\begin{array}{rrr|r}1&5&5&2\\2&2&-3&-1\\-1&-9&2&9\end{array}
\right)
\xrightarrow{f_2 - 2 f_1 \rightarrow f_2}
\left(
\begin{array}{rrr|r}1&5&5&2\\0&-8&-13&-5\\-1&-9&2&9\end{array}
\right)
\rightarrow  \\
\xrightarrow{f_3 + f_1 \rightarrow f_3}
\left(
\begin{array}{rrr|r}1&5&5&2\\0&-8&-13&-5\\0&-4&7&11\end{array}
\right)
\xrightarrow{f_3 - \frac12 f_2 \rightarrow f_3}
\left(
\begin{array}{rrr|r}1&5&5&2\\0&-8&-13&-5\\0&0&\frac{27}{2}&\frac{27}{2}\end{array}
\right)
\end{align*}


Ahora podemos obtener los valores de $x, y, z$ por "sustitución hacia atrás". Primero calculamos $z = 1$, luego $y = -1$ y finalmente $x = 2$. La segunda ecuación queda

$$
-8y -13 \cdot (1)=-5
$$

entonces, $y = -1$.

%Algorítmicamente podemos describir el proceso con los siguientes pasos para resolver el sistema $\Ab \xb = \bb$, con $\Ab \in \R^{m \times n}$ y $\bb \in \R^n$:
%\begin{enumerate}
%\item Construimos la matriz ampliada $\Ab_1$, agregando a $\Ab$ el vector $\bb$ como \'ultima columna.
%\item Para $k = 1, \dots, m-1$:
%\begin{enumerate}
%\item \label{ciclo}Consideramos la primer $\Ab_k$ formada por las filas desde la fila $k$ hasta la fila $m$ de $\Ab_1$.
%\item Consideramos la primer columna no nula de la matriz $\Ab_k$.
%\item Realizando operaciones permitidas de filas, obtenemos 0's abajo de la primera casilla de esa columna.
%\end{enumerate}
%\item Devolvemos la matriz escalonada $\Ab_{m-1}$.
%\end{enumerate}
%
\begin{ejemplo}
Resolvemos escalonando el sistema
$$
\left\{
\begin{aligned}
x_1 + 2x_2 - x_3 &= -1 \\
2x_1 + 4x_2 + 3 x_3 &= 4 \\
3 x_3 &= 6.
\end{aligned}
\right.
$$
%$\begin{pmatrix} 1 & 2 & 0 \\ 2 & 4 & 3 \\ 0 & 0 & 3 \end{pmatrix} x = \begin{pmatrix} -1 \\ 4 \\ 6 \end{pmatrix}$.

\begin{enumerate}
\item Construimos la matriz ampliada
$$\tilde \Ab = \left( \begin{array}{ccc|c}
1 & 2 & -1 & -1 \\ 2 & 4 & 3 & 4 \\ 0 & 0 & 3 & 6 \end{array} \right).$$
\item Para conseguir 0's abajo de la casilla $(1,1)$, realizamos la operación $f_2 - 2f_1 \rightarrow f_2$.  Obtenemos
$$\tilde \Ab_1 = \left( \begin{array}{ccc|c}
1 & 2 & -1 & -1 \\ 0 & 0 & 3 & 6 \\ 0 & 0 & 3 & 6 \end{array} \right).$$

\item Como deseamos tener en cada fila m\'as ceros que en la anterior, debemos ahora obtener un 0 abajo de la casilla $(2, 3)$. Para eso realizamos la operaci\'on $f_3 - f_2 \rightarrow f_3$.  Obtenemos la matriz
$$
\tilde \Ab_2 = \left( \begin{array}{ccc|c} 1 & 2 & -1 & -1 \\ 0 & 0 & 3 & 6 \\ 0 & 0 & 0 & 0 \end{array}\right),
$$
que es una matriz escalonada, por lo que finalizamos el proceso.
\end{enumerate}

Observar que si bien la matriz $\tilde \Ab_1$ tiene 0's abajo de la diagonal, no es un matriz escalonada porque las filas 2 y 3 tienen la misma cantidad de 0's iniciales.

Ahora podemos resolver el sistema despejando las ecuaciones que obtuvimos:
$$ \left\{
\begin{aligned}
x_1 + 2 x_2 - x_3 &= -1 \\
3 x_3 &= 6,
\end{aligned}
\right.
$$
de donde despejamos $x_3 = 2$ y $x_1 = -1 - 2 x_2 + x_3 = 1-2x_2$. El conjunto de soluciones del sistema es
$$
S = \{(1-2x_2, x_2, 2): x_2 \in \R\}.
$$
\end{ejemplo}


En los paquetes comunes de \python no existe un comando para realizar eliminación gaussiana (aunque sí existen comandos para resolver sistemas lineales eficientemente). Más adelante, cuando avancemos con las técnicas de programación y desarrollo de algoritmos, podremos programar nuestro propio programa de eliminación gaussiana. Por el momento, utilizaremos el siguiente programa, extraido de la página \url{https://math.stackexchange.com/questions/3073083/how-to-reduce-matrix-into-row-echelon-form-in-python/3073117}.

El nombre de la función es \texttt{row\_echelon}, que es el nombre en inglés para una matriz escalonada por filas. Para utilizar esta función, pueden copiar y pegar el código en una celda y ejecutarlo, o grabarlo en un archivo \texttt{row\_echelon.py} y cargarlo mediante el comando \texttt{import row\_echelon}.

\begin{Shaded}
\begin{lstlisting}[language=Python]
def row_echelon(M):
    """ Return Row Echelon Form of matrix A """

    A = M.astype(float)
    # if matrix A has no columns or rows,
    # it is already in REF, so we return itself
    r, c = A.shape
    if r == 0 or c == 0:
        return A

    # we search for non-zero element in the first column
    for i in range(len(A)):
        if A[i,0] != 0:
            break
    else:
        # if all elements in the first column are zero,
        # we perform REF on matrix from second column
        B = row_echelon(A[:,1:])
        # and then add the first zero-column back
        return np.hstack([A[:,:1], B])

    # if non-zero element happens not in the first row,
    # we switch rows
    if i > 0:
        ith_row = A[i].copy()
        A[i] = A[0]
        A[0] = ith_row

    # we divide first row by first element in it
    A[0] = A[0] / A[0,0]
    # we subtract all subsequent rows with first row
    #(it has 1 now as first element)
    # multiplied by the corresponding element in the first column
    A[1:] -= A[0] * A[1:,0:1]

    # we perform REF on matrix from second row, from second column
    B = row_echelon(A[1:,1:])

    # we add first row and first (zero) column, and return
    return np.vstack([A[:1], np.hstack([A[1:,:1], B]) ])
\end{lstlisting}
\end{Shaded}

Probamos el programa en el siguiente ejemplo.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])
print(row_echelon(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
[[1. 2. 3. 4.]
 [0. 1. 2. 3.]
 [0. 0. 0. 0.]]
\end{verbatim}

Si queremos armar la matriz ampliada correspondiente a un sistema de ecuaciones y tenemos la matriz $\Ab$ de coeficientes y el vector $\bb$ de términos independientes, podemos usar el comando \texttt{c\_} de \texttt{numpy} para pegar a $\Ab$ el vector $\bb$ como última columna.

\begin{ejemplo}
Resolvemos en \python el sistema
$$
\left\{
\begin{aligned}
x_1 + 5x_2 + 5x_3 &= -2 \\
2x_1 + 2x_2 - 3 x_3 &= -1 \\
-x_1 - 9 x_2 + 2 x_3 &= 9.
\end{aligned}
\right.
$$

%$$
%\begin{pmatrix}
%1 & 5 & 5 \\
%2 & 2 & -3 \\
%-1 & -9 & 2
%\end{pmatrix}
%\begin{pmatrix}
%x_1 \\
%x_2 \\
%x_3
%\end{pmatrix} =
%\begin{pmatrix}
%2 \\
%-1 \\
%9
%\end{pmatrix}.
%$$

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1,5,5],[2,2,-3],[-1,-9,2]])
b = np.array([2, -1, 9])
Ab = np.c_[A, b] # Las matrices o vectores van entre corchetes.
print("Ab = \n", Ab)

print("Matriz escalonada: \n", row_echelon(Ab))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% Ab =
%%  [[ 1  5  5  2]
%%  [ 2  2 -3 -1]
%%  [-1 -9  2  9]]
%% Matriz escalonada:
%%  [[1.    5.    5.    2.   ]
%%  [0.    1.    1.625 0.625]
%%  [0.    0.    1.    1.   ]]
\end{verbatim}
\end{ejemplo}

Despejando de abajo hacia arriba, obtenemos
$$
\begin{aligned}
x_3 &= 1 \\
x_2 &= 0.625 - 1.625 x_3 = -1 \\
x_1 &= 2 - 5 x_2 - 5 x_3 = 2.
\end{aligned}
$$

\subsection{Clasificación de sistemas de ecuaciones}

Estudiamos ahora cuántas soluciones puede tener un sistema de ecuaciones a partir de la forma escalonada de la matriz ampliada.
%tiene el sistema $\Ab \xb = \bb$ a partir de $\Ab$ y $\bb$.


\begin{ejemplo} Resolvemos el siguiente sistema de ecuaciones:

$$
\left\{\begin{aligned}
5x_1 + 3x_2 &= 11 \\
15x_1 + 9x_2 &= 33 \\
20x_1 + 12x_2 &= 44
\end{aligned}\right.
$$

Construimos la matriz ampliada

$$
\left(\begin{array}{rr|r}5&3&11\\15&9&33\\20&12&44\end{array}\right)
$$

y escalonamos usando \python.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[5,3,11],[15,9,33],[20,12,44]])
print(row_echelon(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[1.  0.6 2.2]
%%  [0.  0.  0. ]
%%  [0.  0.  0. ]]
\end{verbatim}
Vemos que se eliminaron las últimas dos ecuaciones, y nos queda solo una
ecuación:
$$
x_1 + 0.6 x_2 = 2.2
$$
de donde podemos despejar $x_1 = 2.2 - 0.6x_2$.

El sistema tiene infinitas soluciones,
$$S = \{(2.2 - 0.6x_2, x_2): x_2 \in \R\}.$$
\end{ejemplo}



\begin{ejemplo}
Consideremos ahora el mismo sistema inicial, modificando un valor en $\bb$:
%Consideremos el siguiente sistema de ecuaciones:
$$
\left\{
\begin{aligned}
5x_1 + 3x_2 &= 11 \\
15x_1 + 9x_2 &= 33 \\
20x_1 + 12x_2 &= 55
\end{aligned}
\right.
$$


Escalonamos la matriz ampliada:
\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[5,3,11],[15,9,33],[20,12,55]])
print(row_echelon(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[1.  0.6 2.2]
%%  [0.  0.  1. ]
%%  [0.  0.  0. ]]
\end{verbatim}

En la segunda ecuación, obtuvimos $0x_1 + 0x_2 = 1$. ¡Absurdo! El
sistema no tiene solución.
\end{ejemplo}

Si al escalonar la matriz ampliada, llegamos a una ecuación
$$
0 x_1 + \dots + 0x_n = a \neq 0
$$
el sistema no tiene solución. Por el contrario, si en todas las filas
que se anulas los coeficientes de las variables, obtenemos también $0$
en el término independiente, el sistema admite solución (podemos ir
resolviendo hacia atrás).

Obtenemos los siguientes casos para un sistema de $m$ ecuaciones y $n$ incógnitas.
%$\Ab\xb = \bb$, con $\Ab \in \R^{m \times n}$ (es decir, $m$ ecuaciones y $n$ incógnitas)

\begin{itemize}
\item   \textbf{Sistema incompatible.} El sistema no tiene solución. Al
    escalonar obtuvimos una ecuación $0 x_1 + \dots + 0x_n = a \neq 0$.
    Ejemplo:

$$
\left(\begin{array}{rrr|r}5&3&2&11\\0&9&-1 & 10\\0&0&0&4\end{array}\right)
$$

\item   \textbf{Sistema compatible determinado.} El sistema tiene solución única.
    Al escalonar la matriz ampliada, obtenemos exactamente $n$
    ecuaciones no nulas, y podemos obtener la solución despejando las
    variables.\
    %Si $\Ab$ es cuadrada, $\Ab$ es inversible ($\det(\Ab) \neq 0$). Ejemplo:

$$
\left(\begin{array}{rrr|r}5&3&2&11\\0&9&-1 & 10\\0&0&1&2\\0&0&0 & 0\\0&0&0&0\end{array}\right)
$$

\item  \textbf{Sistema compatible indeterminado.} El sistema tiene infinitas
    soluciones. Al escalonar la matriz ampliada obtenemos menos de $n$
    filas no nulas en las primeras $n$ columnas, y el resto de las filas
    son nulas en todas las columnas. Ejemplo:

$$
\left(\begin{array}{rrr|r}5&3&2&11\\0&9&-1 & 10\\0&0&0 & 0\\0&0&0&0\end{array}\right)
$$

\end{itemize}

\begin{ejercicio} Escalonar las siguientes matrices y clasificar el sistema
en (a) incompatible, (b) compatible determinado, (c) compatible
indeterminado.

\begin{multicols}{3}
\begin{enumerate}
\item $\left\{
\begin{aligned}
3y - 2z + 3 w &= 9\\
2x + y + w &= 5\\
x-y+z-w &= -2
\end{aligned}
\right.$
\item $\left\{
\begin{aligned}
x - 2y &= 2\\
2x +  y & =1\\
x + 3y & = -1
\end{aligned}\right.$
\item $\left\{
\begin{aligned}
2x + y -z &= 3\\
x - y +z & = 2\\
5x + y -z &= -5
\end{aligned}\right.$
\end{enumerate}
\end{multicols}
\end{ejercicio}


\section{Espacios vectoriales}
%Una de los principales usos del álgebra lineal es la resolución de ecuaciones lineales. Los sistemas de ecuaciones lineales son el algún sentido los . Los sistemas Actualmente El álgebra lineal
Un espacio vectorial es un conjunto de elementos, llamados \emph{vectores}, que pueden ser sumados entre sí y multiplicados (\emph{escalados}) por números (llamados \emph{escalares}). Llamamos $V$ al conjunto de vectores y $\K$ al conjunto de n\'umeros.

El conjunto $\K$ debe ser un cuerpo. Esto es, $\K$ posee una suma $+$ y un producto $\cdot$ que satisfacen un conjunto de axiomas que podemos resumir en la siguiente tabla.

\begin{center}
\begin{tabular}{ |c|c|c| } \hline
& suma & producto \\ \hline
 asociatividad & $a + (b + c) = (a+b) + c$ & $(a\cdot b) \cdot c = a\cdot (b\cdot c)$ \\ \hline
 conmutatividad & $a + b = b + a$ & $a \cdot b = b \cdot a$ \\ \hline
 propiedad distributiva & \multicolumn{2}{|c|}{$a \cdot (b + c) = a \cdot b + a \cdot c$} \\ \hline
 elemento identidad & $0 + a = a = a + 0$ & $1 \cdot a = a = a \cdot 1$ \\ \hline
 elemento inverso & $a + (-a) = 0$ & $a \cdot (a^{-1}) = 1$ \\ \hline
\end{tabular}
\end{center}


En esta materia trabajaremos con $\K = \R$, el cuerpo de los n\'umeros reales o $\K =  \C$ el cuerpo de los números complejos\footnote{Existen otros ejemplos de cuerpos como los racionales $\mathbb{Q}$ o los enteros módulo un primo $p$, $\mathbb{Z}_p$.}.

\begin{ejemplo}
El conjunto $\Z$ de los números enteros no es un cuerpo, porque excepto $1$ y $-1$, los demás números enteros no poseen un inverso entero para la multiplicación. Por ejemplo, el inverso de $2$ es $1/2$ que no es un número entero.
\end{ejemplo}


Formalmente, un espacio vectorial sobre un cuerpo $\K$  (tambi\'en llamado $\K$ - espacio vectorial) es un conjunto $V$ y dos operaciones, que satisfacen ciertos axiomas.

Las operaciones definidas en $V$ son:

\begin{itemize}
\item Suma de vectores. $+:V \times V \rightarrow V$, a cualquier par $\vb, \wb$ de vectores le asigna un vector $\vb+\wb \in V$.
\item Producto por escalar. $\cdot : \K \times V \rightarrow V$, a un escalar $a$ y un vector $\vb \in V$ le asigna un vector $a\vb \in V$ (no confundir con el producto escalar que dados dos vectores devuelve un escalar que veremos más adelante).
\end{itemize}

Los axiomas de espacio vectorial son

\begin{enumerate}
\item   \textbf{Asociatividad de la suma.} $\ub + (\vb + \wb) = (\ub + \vb) + \wb$
\item   \textbf{Conmutatividad de la suma.} $\ub + \vb = \vb + \ub$
\item   \textbf{Elemento neutro de la suma.} Existe un elemento $\cero \in V$ tal que $\vb + \cero = \vb$ para todo $\vb \in V$.
\item   \textbf{Inverso para la suma.} Para todo $\vb \in V$, existe un elemento $-\vb \in V$, llamado inverso aditivo de $\vb$, tal que $\vb + (-\vb) = 0$.
\item   \textbf{Compatibilidad de la multiplicación por escalar con la la multiplicación del cuerpo.} $a(bv) = (ab)\vb$.
\item   \textbf{Elemento neutro de la multiplicación por escalar.} $1 \vb = \vb$, donde $1$ es el neutro de $\R$.
\item   \textbf{Propiedad distributiva de la multiplicación por escalar respecto de la suma de vectores.} $a(\ub+\vb) = au + av$.
\item   \textbf{Propiedad distributiva de la multiplicación por escalar respecto de la suma de escalares.} $(a+b)(\vb) = av + bv$.
\end{enumerate}

\begin{ejemplo}
Los siguientes conjuntos son espacios vectoriales definiendo la suma y el producto por escalar de modo "tradicional".
\begin{enumerate}
\item $\K^n$, es un $\K$ espacio vectorial.
\item $\K^{m \times n}$, el conjunto de matrices, es un $\K$ espacio vectorial.
\item $\K[x]$ el conjunto de todos los polinomios en una variable a coeficientes reales o complejos.
\item $\R[x]_d$, el conjunto de polinomios en una variable de grado menor o igual que $d$.
\item $(a_1, a_2, a_3, \dots)$, el conjunto de sucesiones infinitas de números reales o complejos.
\item $\K$ es un $\K$ espacio vectorial. Pero note que $\C$ tambi\'en es un $\R$ espacio vectorial.
\end{enumerate}

Los siguientes conjuntos \emph{no} son espacios vectoriales.
\begin{enumerate}
\item El conjunto de matrices de cualquier tamaño.
\item Los polinomios de grado exactamente $d$.
\end{enumerate}
\end{ejemplo}

\begin{aplicacion}
Veamos un ejercicio sencillo de aplicación de espacios vectoriales.
Se quiere predecir el consumo en tarjeta de crédito que tendrán los clientes de un banco mediante un modelo lineal.
Para eso, se consideran las siguientes \emph{variables explicativas} de los clientes:

\begin{enumerate}
\item Sueldo mensual
\item Impuesto a las ganancias pagado el año anterior.
\item Cantidad de integrantes del grupo familiar
\item Puntaje otorgado a la serie "La Casa de Papel" (1 a 5 estrellas)
\item Es fumador (sí / no)
\item Marca de Celular (Samsung / Huawei / Iphone / Otro)
\end{enumerate}

Se quiere definir un espacio vectorial $V$ donde la información de cada cliente sea un vector de $V$. ¿Qué espacio vectorial utilizaría para este modelo? (Se busca que dos personas con vectores similares tengan comportamiento similar.)

Observamos que los cuatro primeros datos son datos num\'ericos y podemos representar cada valor con un número real. En las preguntas 3 y 4, nos gustaría utilizar números enteros para representar los valores, pero ya vimos que el conjunto de números enteros no es un cuerpo y por lo tanto no podemos definir un espacio vectorial sobre los enteros.

La quinta pregunta podemos representarla con valores 0 y 1. En este caso al conjunto $\{0, 1\}$ podemos asignarle estructura de cuerpo, pero dado que queremos un único espacio vectorial para representar todas las variables, debemos representar estos valores también como números reales.

Finalmente, para el último dado, podríamos asignarle un valor numérico a cada respuesta: 1 = Samsung, 2 = Huawei, 3 = Iphone, 4 = Otro, sin embargo esto no cumpliría lo que buscamos en nuestro modelo que vectores similares tengan comportamiento similar. Es decir, si usamos esta representación estaríamos indicando que la respuesta Otro es muy similar a Iphone y no tan similar a Samsung, y en principio no hay razón para esa suposición. Por lo tanto es común en este caso usar las llamadas variables indicadoras, que toman valores 0-1. Utilizamos 4 variables 0-1 que valen 1 en caso de que la respuesta corresponda a esa marca.

¿Qué vector $\vb \in V$ asignaría al cliente con las siguientes características?
\begin{enumerate}
\item Sueldo mensual: \$80.000
\item Impuesto a las ganancias pagado el año anterior: \$100.000
\item Cantidad de integrantes del grupo familiar: 4
\item Puntaje otorgado a la serie "La Casa de Papel" (1 a 5 estrellas): 4 estrellas
\item Es fumador (sí / no): sí
\item Marca de Celular (Samsung / Huawei / Iphone / Otro): Huawei
\end{enumerate}

En base a lo que vimos, asignamos a estas respuestas el vector $\vb = (80000, 100000, 4, 4, 1, 0, 1, 0, 0)$.
Esta asignación que hicimos es muy común cuando construimos modelos lineales. Vemos que la estructura de espacio vectorial es la que nos dice cómo construir el modelo.
\end{aplicacion}


\subsection{Subespacios vectoriales}


Dado $V$ un $\K$ espacio vectorial, un subconjunto $U\subset V$ se llama subespacio de $V$ si verifica
\begin{enumerate}
\item $\cero \in U$
\item $\forall \ub,\vb \in U$ $\ub+\vb\in U$
\item $\forall \ub \in U$, $\forall \alpha \in\K$ $\alpha \ub \in U$.
\end{enumerate}
Notar que  $U$  es a la vez un espacio vectorial.

\begin{ejemplo}
Algunos ejemplos de subespacios vectoriales son
\begin{enumerate}
\item El subconjunto de vectores de $\mathbb{R}^5$ tales que la primera coordenada es $0$ es un subespacio vectorial de $\mathbb{R}^5$.
\item El conjunto de matrices diagonales de $3 \times 3$ es un subespacio vectorial de $\mathbb{R}^{3 \times 3}$.
\item El conjunto de matrices simétricas de $n \times n$ es un subespacio vectorial de $\mathbb{R}^{n \times n}$.
\item El subconjunto de vectores $\mathbb{R}^5$ tales que la primera coordenada es $1$ \textbf{no} es un subespacio vectorial de $\R^5$.
\item El conjunto de todos los polinomios en $\R[X]$ que se anulan en $1$.
\end{enumerate}
\end{ejemplo}

\subsection{Conjuntos de generadores y bases}

\subsubsection{Vectores linealmente independientes}

Dado un conjunto $\{\vb_1, \dots, \vb_m\}$ de vectores en $\mathbb{R}^n$, decimos que es un conjunto de vectores linealmente independientes si la única elección de coeficientes para los cuales

$$\sum_{i=1}^m a_i \vb_i = 0$$

es $a_i = 0$ para todo $1 \le i \le m$.

\begin{ejemplo}\leavevmode
\begin{itemize}
\item Los vectores $\vb_1 = (1,0,0)$, $\vb_2 = (0, 1, 0)$ y $\vb_3 = (0, 0, 1)$ son linealmente independientes.
\item Los vectores $\vb_1 = (1,0,1)$, $\vb_2 = (0, 1, 2)$ y $\vb_3 = (1, 2, 5)$ son linealmente dependientes, porque $\vb_3 = \vb_1 + 2\vb_2$. O equivalentemente, $\vb_1 + 2\vb_2 - \vb_3 = 0$.
\end{itemize}
\end{ejemplo}

\subsubsection{Espacio vectorial generado por vectores}
Dado un conjunto de vectores $\{\vb_1, \dots, \vb_m\}$ de un espacio vectorial $V$, el conjunto de todas las combinaciones lineales de estos vectores
$$
\langle \vb_1, \dots, \vb_m \rangle = \{a_1 \vb_1 + \dots + a_m \vb_m : a_i \in \mathbb{R}, i = 1, \dots, m\}
$$
es un subespacio $U$ de $V$ llamado el espacio generado por $\{\vb_1, \dots, \vb_m\}$.

\begin{proposicion}
Si los vectores $\{\vb_1, \dots, \vb_m\}$ son linealmente independientes, cualquier elemento de $U = \langle \vb_1, \dots, \vb_m \rangle$ se escribe de forma única como combinación lineal de los vectores $\{\vb_i: i = 1, \dots, m\}$.
\end{proposicion}

\begin{proof}
Supongamos por el absurdo que $\vb$ puede escribirse de dos formas distintas $\vb = a_1 \vb_1 + \dots + a_m \vb_m = b_1 \vb_1 + \dots + b_m \vb_m$, entonces restando obtenemos
$$
0 = (a_1-b_1) \vb_1 + \dots + (a_m-b_m) \vb_m,
$$
donde los coeficientes no son todos 0 (porque $(a_1, \dots, a_m) \neq (b_1, \dots, b_m)$), y esto contradice la independencia lineal de los vectores $\{\vb_1, \dots, \vb_m\}$.
\end{proof}


\begin{definicion}
Si $\B = \{\vb_1, \dots, \vb_m\} \subset V$ es un conjunto linealmente independiente, decimos que $\B$ es una \emph{base} de $U = \langle \vb_1, \dots, \vb_m \rangle \subset U$.
\end{definicion}

A continuación veremos que si un espacio vectorial $V$ tienen una base con una cantidad finita de elementos, cualquier otra base de $V$ tiene la misma cantidad de elementos.

Comenzamos con el siguiente lema.

\begin{proposicion}[Lema de intercambio]
Si $\B = \{\vb_1, \dots, \vb_m\}$ es un base de $V$ y $\wb \in V$, entonces existe $1 \le i \le m$ tal que reemplazando en $\B$ a $\vb_i$ por $\wb$, el conjunto resultante sigue siendo una base de $V$.
\end{proposicion}

\begin{proof}
Como $\wb \in V$ y $\B$ es una base, existen $a_1, \dots, a_m$ en $\K$ tales que
$$ \wb= a_1 \vb_1 + \dots + a_m \vb_m,$$
y existe algún $1 \le k \le m$ tal que $a_k \neq 0$. Por lo tanto,
$$
\vb_k = \frac{1}{a_k}\left( \wb - \sum_{i \neq k} a_i \vb_i\right),
$$
y el conjunto $\{\vb_1, \dots, \wb, \dots, \vb_m\}$ es un sistema de generadores de $V$.

Para ver que forman una base, veamos que son linealmente independientes. Si existe una combinación no nula
$$
b_1 \vb_1 + \dots + b_k \wb + \dots + b_m \vb_m = 0,$$
analizamos dos casos:
\begin{itemize}
\item Si $b_k = 0$, encontramos una relación de dependencia lineal en $\B$, lo cual es absurdo porque $\B$ era una base.
\item Si $b_k \neq 0$, entonces despejando $\wb$ obtenemos una escritura de $\wb$ en la base $\B$ distinta a la anterior, lo cual tambi\'en es absurdo.
\end{itemize}

Concluimos que $\{\vb_1, \dots, \wb, \dots, \vb_m\}$ es un conjunto linealmente independiente y genera $V$, por lo tanto es una base de $V$.
\end{proof}

Ahora podemos probar el siguiente resultado.

\begin{proposicion}
Dado un espacio vectorial $V$, sea $\B = \{\vb_1, \dots, \vb_s\}$ una base de $V$ de $s$ elementos, y sea $\tilde\B$ otra base de $V$. Luego $\tilde\B$ tiene exactamente $s$ elementos.
\end{proposicion}
\begin{proof}
Queremos usar el Lema de Intercambio e ir reemplazando uno a uno los vectores de $\B$ por los vectores de $\tilde\B$. El \'unico cuidado que tenemos que tener es que vayamos reemplazando en cada paso un vector distinto de $\B$.
Para ver que esto siempre es posible, supongamos que ya reemplazamos $k$ vectores y, por simplicidad, supongamos que reemplazamos los primeros $k$ vectores de $\B$ por los primeros $k$ vectores de $\tilde\B$.. Es decir, tenemos que
$$
\{\wb_1, \dots, \wb_k, \vb_{k+1}, \dots, \vb_s\}
$$
es una base de $V$.

Ahora queremos reemplazar a $\wb_{k+1}$ por alg\'un vector $\vb_i$, $i \ge k+1$. Siguiendo la demostración del Lema de Intercambio, escribimos a $\wb_{k+1}$ como combinaci\'on no nula de los elementos de la base:
$$ \wb_{k+1} = c_1 \wb_1 + \dots + c_k \wb_k + c_{k+1} \vb_{k+1} + \dots + c_s \vb_s.$$
No pueden ser todos los coeficientes $c_{k+1}, \dots, c_s$ iguales a 0, porque entonces $\tilde\B$ no sería base de $V$. Luego podemos elegir $j > k$ tal que $c_j \neq 0$, y siguiendo la demostraci\'on del Lema de Intercambio, obtenemos que reemplazando a $\vb_j$ por $\wb_k$ obtenemos una nueva base de $V$.

Aplicando este razonamiento inductivamente, concluimos que existen $\{\wb_1, \dots, \wb_s\} \subset \tilde\B$ que forman una base de $V$. Por lo tanto $\tilde\B$ es exactamente igual a $\{\wb_1, \dots, \wb_s\}$, y tiene $s$ elementos.
\end{proof}

Cuando $V$ tiene una base finita, llamamos dimensión de $V$ a la cantidad de elementos de la base, y decimos que $V$ es un espacio de dimensión finita.

\begin{ejemplo}\leavevmode
\begin{enumerate}
\item $\mathbb{R}^n$ es un espacio vectorial de dimensión $n$. Una base de $\mathbb{R}^n$ es $\{\eb_i: i = 1, \dots, n\}$, con $\eb_i$ el vector que tiene $1$ en la entrada $i$ y $0$ en todas las demás. Llamamos base canónica a esta base.
\item $\mathbb{R}[x]_d$ es un espacio vectorial de dimensión $d+1$. La base canónica de $\mathbb{R}[x]_d$ es $\{1, x, x^2, \dots, x^d\}$.
\item $\mathbb{R}[x]$ es un espacio vectorial de dimensión infinita.
\end{enumerate}
\end{ejemplo}

En esta materia vamos a trabajar sobre espacios de dimensión finita.

\begin{proposicion}
 Todo $\mathbb{R}$-espacio vectorial de dimensión finita $n$ es isomorfo a $\mathbb{R}^n$ como espacio vectorial (es decir, si solo consideramos las operaciones de espacio vectorial).
 \end{proposicion}

\begin{ejemplo} \leavevmode
\begin{enumerate}
\item Las matrices de $m \times n$ podemos pensarlas como vectores de longitud $m \times n$.
\item Los polinomios de grado $d$ podemos representarlos por sus vectores de coeficientes, de longitud $d + 1$. Por ejemplo, en $\R[x]_3$ representamos al polinomio $x^3 -3x + 2$ por el vector $(1, 0, -3, 2)$.
\end{enumerate}
\end{ejemplo}

En general, si $\B = \{\bb_1, \dots, \bb_n\}$ es una base de un espacio vectorial $V$ y $\vb \in V$, vimos que $\vb$ admite una escritura única como combinación lineal de elementos de $\B$, $\vb = a_1 \bb_1 + \dots + a_n \bb_n$. Podemos representar a $\vb$ en la base $\B$ como $\vb = (a_1, \dots, a_n)_{\B}$.

Por ejemplo, $p(x) = x^3-3x+2 = (1, 0, -3, 2)_{\B}$, con $\B= \{x^3, x^2, x, 1\}$.

\subsection{Base a partir de sistema de generadores}

Como vimos, para un espacio vectorial $V$ de dimensión finita $n$, cualquier base de $V$ tiene la misma cantidad de elementos $n$.
Esto implica los siguientes resultados directos, cuya demostración dejamos como ejercicio.
\begin{itemize}
\item Un conjunto $S \subset V$ con menos de $n$ elementos no puede generar todo $V$.
\item Si $S \subset V$ es un conjunto linealmente independiente de $n$ elementos, $S$ es una base de $V$.
\item Un conjunto $S \subset V$ con más de $n$ elementos no puede ser linealmente independiente.
\end{itemize}

M\'as a\'un, tenemos el siguiente resultado.

\begin{proposicion} \label{prop:subbase}
Si $V$ es un espacio de dimensi\'on $n$ y $S \subset V$ es un conjunto de generadores de $m$ elementos, con $m > n$, podemos extraer de $S$ un subconjunto $\B$ de $n$ elementos que forma una base de $V$.
\end{proposicion}

\begin{proof}
Veamos que si $m > n$, podemos eliminar alg\'un vector de $S$ y seguir teniendo un sistema de generadores.
Como $S$ no puede ser un conjunto linealmente independiente, existe una combinación lineal no nula
$$
0 = a_1 \wb_1 + \dots + a_s \wb_s,
$$
y suponemos por simplicidad $a_s \neq 0$. Luego $\wb_s$ pertenece al espacio generado por $\{\wb_1, \dots, \wb_{s-1}\}$, y por lo tanto podemos eliminarlo.

Podemos repetir este proceso inductivamente siempre que la cantidad de vectores resultantes sea mayor que $n$, hasta llegar a tener un subconjunto de $n$ elementos que generan $V$ y por lo tanto es una base de $V$.
\end{proof}

Notamos también que dado un conjunto de vectores $S = \{\vb_1, \dots, \vb_s\}$, podemos obtener una base del espacio vectorial generado por $S$ triangulando el sistema, es decir
\begin{enumerate}
\item Colocamos los vectores como filas de una matriz.
\item Triangulamos la matriz utilizando eliminación gaussiana.
\item Tomamos los vectores correspondientes a las filas no nulas de la matriz.
\end{enumerate}

\begin{ejemplo}
Dado el subespacio $S = \langle( 1,  4,  3, -1), (1,  0,  1,  0), (3,  3,  2,  7), (2,  6,  0, 14),( 2,  3,  1,  7)\rangle \subset \R^4$, para obtener una base de $S$ construimos la matriz
$$
A =
\begin{pmatrix}
 1 & 4 & 3 & -1 \\
 1 & 0 & 1 &  0 \\
 3 & 3 & 2 &  7 \\
 2 & 6 & 0 & 14 \\
 2 & 3 & 1 &  7
\end{pmatrix}
$$
y triangulamos.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1, 4, 3, -1,], [1, 0, 1, 0], [3, 3, 2, 7], [2, 6, 0, 14], [2, 3, 1, 7]])
print(row_echelon(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[ 1.    4.    3.   -1.  ]
%%  [ 0.    1.    0.5  -0.25]
%%  [ 0.    0.    1.   -3.1 ]
%%  [ 0.    0.    0.    0.  ]
%%  [ 0.    0.    0.    0.  ]]
\end{verbatim}

Obtenemos la matriz
$$
A' =
\begin{pmatrix}
 1 & 4 & 3 & -1 \\
 0 & 1 & 1/2 &  -1/4 \\
 0 & 0 & 1 &  -31/10 \\
 0 & 0 & 0 & 0 \\
 0 & 0 & 0 & 0
\end{pmatrix}.
$$

Por lo tanto una base de $S$ es $\B = \{(1, 4, 3, -1), (0, 1, 1/2, -1/4), (0, 0, 1, -31/10)\}$.
\end{ejemplo}

A partir de la Proposici\'on \ref{prop:subbase}, podemos deducir el siguiente resultado de extensión de una base.

\begin{proposicion}[Extensión de una base]
\label{prop:extension}
Dado un espacio vectorial $V$ de dimensión $n$ y una base $\B = \{\vb_1, \dots, \vb_s\}$ de un subespacio $S \subset V$, es posible encontrar vectores $\{\wb_1, \dots, \wb_{n-s}\}$ tales que
$$
\{\vb_1, \dots, \vb_s, \wb_1, \dots, \wb_{n-s}\}
$$
forman una base de $V$.
\end{proposicion}
\begin{proof} Ejercicio.
\end{proof}

%\subsubsection{Operaciones de espacio vectorial}
%
%Las operaciones de espacio vectorial son:
%
%\begin{itemize}
%\item Suma de vectores o matrices del mismo tamaño.
%\item Producto de vectores o matrices por un \emph{escalar} (un número del cuerpo $\K$).
%\end{itemize}
%

\subsection{Espacios dados por ecuaciones homog\'eneas}

Dado un sistema de ecuaciones $\Ab \xb = \cero$, con $\Ab \in \R^{m \times n}$ y $\cero \in \R^m$ el vector nulo, es fácil ver que el conjunto $S$ de soluciones es un subespacio vectorial de $\R^n$.

Por lo tanto, podemos encontrar una base de $S$ como subespacio de $\R^n$. Una forma de encontrar una base es triangular el sistema. Cada fila no nula en la matriz escalonada impone una restricción en el espacio y reduce en uno la dimensión. Es decir, que la dimensión de $S$ es $n - k$ donde $k$ es la cantidad de filas no nulas en la triangulación.

\begin{ejemplo}
El sistema
$$ \left\{
\begin{aligned}
x_1 + 2 x_2 - x_3 + x_4&= 0 \\
3 x_2 - 2 x_3 - x_4 &= 0,
\end{aligned}
\right.
$$
ya está escalonado. Por lo tanto el espacio de soluciones tiene dimensión $4 -2  = 2$.

Para encontrar un sistema de generadores, despejamos la primera variable de cada ecuación en el sistema triangulado en función de las demas variables. Llamamos \emph{variables dependientes} a las variables que aparecer como primer variable de alguna fila, y variables libres o independientes a las dem\'as. En este ejemplo, $\{x_1, x_2\}$ son las variables dependientes y $\{x_3, x_4\}$ las variables libres (estos conjuntos dependen del método que utilizamos para resolver el sistema, podemos obtener otros conjuntos de variables dependientes y libres, aunque la cantidad de variables en cada uno será siempre la misma).

Ahora despejamos las variables dependientes en función de las variables libres, de abajo para arriba:
$$\left\{
\begin{aligned}
x_2 &= \frac{2x_3 + x_4}{3} = \frac{2}{3} x_3 + \frac{1}{3} x_4 \\
x_1 &= -2x_2 + x_3 - x_4 = -2\left(\frac{2}{3} x_3 + \frac{1}{3} x_4\right) + x_3 - x_4 = -\frac{1}{3} x_3 - \frac{5}{3} x_4,
\end{aligned}
\right.
$$
y podemos escribir el conjunto de soluciones en la forma
$$
S =\left\{\left(-\frac{1}{3} x_3 -\frac{5}{3} x_4, \frac{2}{3} x_3 + \frac{1}{3} x_4, x_3, x_4\right): x_3, x_4 \in \R\right\}.
$$

A partir de esta escritura, es fácil obtener los generadores del subespacio vectorial:
$$
\begin{aligned}
S &=\left\{\left(-\frac{1}{3} x_3, \frac{2}{3} x_3, x_3, 0\right) + \left(-\frac{5}{3} x_4, \frac{1}{3} x_4, 0, x_4\right): x_3, x_4 \in \R\}.: x_3, x_4 \in \R\right\} \\
&=\left\{\left(-\frac{1}{3}, \frac{2}{3} , 1, 0\right)x_3 + \left(-\frac{5}{3}, \frac{1}{3} , 0, 1\right) x4: x_3, x_4 \in \R\}.: x_3, x_4 \in \R\right\},
\end{aligned}
$$
y concluimos $S = \langle \left(-\frac{1}{3}, \frac{2}{3} , 1, 0\right), \left(-\frac{5}{3}, \frac{1}{3} , 0, 1\right)\rangle$.
\end{ejemplo}


\subsection{Ecuaciones a partir de generadores}

En la sección anterior, vimos cómo obtener los generadores de un subespacio vectorial dado por ecuaciones homogéneas.
En ocasiones es \'util realizar el proceso inverso, obtener ecuaciones homogéneas que definen un espacio vectorial dado por generadores.

Veamos c\'omo hacerlo en un ejemplo.

\begin{ejemplo}
Hallar las ecuaciones que definen el espacio generado por los vectores $S = \{(1, 0, 2, -1), (3, 1, 0, 2)\}$.
Un vector gen\'erico de $S$ es
$$
(x_1, x_2, x_3, x_4) = a_1 (1, 0, 2, -1) + a_2 (3, 1, 0, 2).
$$

Podemos platear esta ecuaci\'on en forma matricial:
$$
\begin{pmatrix}
1 & 3 \\
0 & 1 \\
2 & 0 \\
-1 & 2
\end{pmatrix}
\begin{pmatrix}
a_1 \\
a_2
\end{pmatrix}
=
\begin{pmatrix}
x_1 \\
x_2 \\
x_3 \\
x_4
\end{pmatrix}.
$$

Ahora buscamos relaciones entre los $x_i$. Para eso triangulamos la matriz ampliada
$$
\left(
\begin{array}{cc|c}
1 & 3 & x_1 \\
0 & 1 & x_2 \\
2 & 0 & x_3 \\
-1 & 2 & x_4
\end{array}
\right).
$$

Al realizar la triangulación, obtenemos la matriz
$$
\left(
\begin{array}{cc|c}
1 & 3 & x_1 \\
0 & 1 & x_2 \\
0 & 0 & x_3 - 2 x_1 + 3x_2\\
0 & 0 & x_4 + x_1 + 5 x_2
\end{array}
\right),
$$
de donde obtenemos las relaciones:
$$
\left\{
\begin{aligned}
x_3 - 2 x_1 + 3x_2 &= 0\\
x_4 + x_1 + 5 x_2 &= 0
\end{aligned}
\right.
$$
y estas son las ecuaciones que definen nuestro espacio vectorial, es decir,
$$
S = \{(x_1, x_2, x_3, x_4): - 2 x_1 + 3x_2 + x_3 = 0, x_1 + 5 x_2 + x_4 = 0 \}.
$$
\end{ejemplo}

En general, dados generadores de un espacio vectorial $S = \langle \vb_1, \dots, \vb_s \rangle \subset \R^n$, realizamos los siguientes pasos para obtener ecuaciones que definen a $S$.
\begin{enumerate}
\item Construir la matriz ampliada correspondiente al sistema de ecuaciones
$$
(x_1, \dots, x_n) = a_1 \vb_1 + \dots + a_s \vb_s.
$$
\item Escalonar la matriz.
\item El espacio $S$ queda definido por las ecuaiones correspondientes a los términos de la \'ultima columna de las filas en las que todos los coeficientes en las primeras $s$ columnas son nulos.
\end{enumerate}

\subsection{Suma e intersecci\'on de subespacios}

Como aplicación de las últimas dos secciones veamos cómo calcular sumas e intersecciones de subespacios vectoriales.

\tccdefi
\begin{definicion}
Dados subespacios $S, T$ de un $\K$ espacio vectorial $W$, definimos
\begin{itemize}
\item \textbf{Suma.} $S + T = \{ \sbb + \tbb : \sbb \in S, \tbb \in T\}$, el conjunto de todas las sumas posibles entre un elemento de $S$ y un elemento de $T$.
\item \textbf{Intersección.} $S \cap T = \{ \vb \in W: \vb \in S \text{ y } \vb \in T\}$.
\end{itemize}
\end{definicion}
\etcc
Queda como ejercicio verificar que estos dos conjuntos son subespacios vectoriales de $W$.

Concentremos un poco nuestra atención en el caso en que $W=\K^n$. Dependiendo si $S$ y $T$ vienen dados por generadores o ecuaciones puede ser más fácil o más difícil calcular estos subespacios. Podemos resumir los métodos de la siguiente forma (dejamos como ejercicio verificar la correctitud de los métodos).

\begin{itemize}
\item Si $S$ y $T$ est\'an dados por generadores, $S + T$ est\'a generado por la unión de todos los generadores.
\item Si $S$ y $T$ est\'an dados por ecuaciones, $S \cap T$ est\'a generado por la unión de todas las ecuaciones.
\item Si $S$ y/o $T$ est\'an dados por ecuaciones, calculamos generadores de ambos y tomamos la unión.
\item Si $S$ y/o $T$ est\'an dados por generadores, calculamos ecuaciones de ambos y tomamos la unión de las ecuaciones.
\end{itemize}

Con métodos similares podemos realizar otras operaciones entre subespacios. Por ejemplo, ¿cómo podemos determinar si $S \subset T$? Ahora el caso más simple es si $S$ está dado por generadores y $T$ por ecuaciones. En este caso, alcanza verificar si todos los generadores de $S$ son elementos de $T$ verificando si cumplen las ecuaciones que definen a $T$.

\begin{ejercicio}
Dados los subespacios de $\R^4$, 
$$S = \langle (1, 0, -3, 1), (2, 0, 3, -2)\rangle \quad \text{ y } \quad T = \{(x_1, x_2, x_3, x_4): x_1+x_2-x_4 = 0, x_2 + x_3 = 0\},$$
hallar generadores de $S+T$ y $S \cap T$. Determinar si $S \subset T$.
\end{ejercicio}
Es simple determinar la relación entre las dimensiones de los espacios $S$,$U$, su suma y su intersección. De eso trata el siguiente resultado.
\begin{proposicion}\label{prop:dimsum}
Sean $U$ y $V$ dos subespacios de un $\K$ espacio vectorial de dimensión finita. Entonces
$$
\dim(U+ V) = \dim(U) + \dim(V) - \dim(U\cap V).
$$
\end{proposicion}
\begin{proof}
Probemos primero el caso en que $U\cap V=\{\cero\}$. En ese caso, $\dim(U\cap V)=0$, por lo cual basta ver que $\dim(U+ V)=\dim(U)+\dim(V)$.

Para ello consideramos $\B=\{\ub_1,\cdots,\ub_k\}$ y $\B'=\{\vb_1,\cdots,\vb_n\}$ bases de $U$ y $V$ respectivamente y notemos que si tomamos un $\wb \in U+V$ deben existir $\ub \in U$ y $\vb\in V$ de modo tal que $\wb=\ub+\vb$. En particular, como $\B$ y $\B'$ son bases de $U$ y $V$,  deben existir escalares $\{\alpha_i\}_{1\le i\le k}$ y $\{\beta_j\}_{1\le j\le n}$ de modo tal que
$$
\ub= \sum_{i=1}^k\alpha_i\ub_i \qquad \vb=\sum_{j=1}^n\beta_j\vb_j,
$$
de donde conclu\'imos que el conjunto
$$\tilde{\B}=\B\cup \B'=\{ \ub_1,\cdots,\ub_k, \vb_1,\cdots,\vb_n\}$$
es un sistema de generadores de $U+V$. Afirmamos que $\tilde{\B}$ es L.I. con lo cual resultaría una base y por ende $\dim(U+V)=\# \B + \#\B'=\dim(U)+\dim(V)$ como queríamos probar. Para ver que $\tilde{\B}$ es L.I. suponemos que para cierta combinación lineal, se tiene
$$
\sum_{i=1}^k\alpha_i\ub_i + \sum_{j=1}^n\beta_j\vb_j=\cero,
$$
y notamos que en ese caso
$$
 U \ni \sum_{i=1}^k\alpha_i\ub_i = \sum_{j=1}^n(-\beta_j)\vb_j \in V,
$$
lo que dice que ambos miembros (que son iguales) pertenecen tanto a $U$ como a $V$ y por ende a $U\cap V=\{\cero\}$. Luego
$$
\sum_{i=1}^k\alpha_i\ub_i = \cero= \sum_{j=1}^n(-\beta_j)\vb_j,
$$
y resulta $\alpha_1=\cdots=\alpha_k=\beta_1=\cdots=\beta_n=0$, indicando que $\tilde{\B}$ es L.I.

Resta probar el caso en que $U\cap V\neq \{\cero\}$. En este caso tomamos una base
$\B''=\{\zb_1,\cdots,\zb_r\}$ de $U\cap V$ y como $U\cap V\subset U$ gracias a la Proposición \ref{prop:extension}, podemos extender $\B''$ a una base $\B$ de $U$,
$\B=\{\zb_1,\cdots,\zb_r, \ub_{r+1},\cdots, \ub_k \}$.  Análogamente, $\B''$ se extiende a una base $\B'$ de $V$, $\B'=\{\zb_1,\cdots,\zb_r, \vb_{r+1},\cdots, \vb_n\}$.  Notemos, antes de proseguir, que las dimensiones de los espacios involucrados son $r$,$k$ y $n$ para  $U\cap V$, $U$ y $V$ respectivamente. Decimos que
 $\tilde{\B}=\{\zb_1,\cdots,\zb_r,\ub_{r+1},\cdots, \ub_k, \vb_{r+1},\cdots, \vb_n\}$ es base de $U+V$. En efecto, es trivial ver que genera y para ver que es L.I. escribimos
 $$
 \sum_{i=1}^r\gamma_i \zb_i +\sum_{j=r+1}^{n}\alpha_j \ub_j +\sum_{l=r+1}^{k}\beta_l \vb_l = \cero,
 $$
 y entonces, por un lado se tiene
 \begin{equation}
 \label{eq:totalsum}
U \ni  \sum_{i=1}^r\gamma_i \zb_i +\sum_{j=r+1}^{k}\alpha_j \ub_j =\sum_{l=r+1}^{n}(-\beta_l) \vb_l \in V,
 \end{equation}
 de donde en particular
 $\sum_{l=r+1}^{n}(-\beta_l) \vb_l \in U\cap V = \langle \zb_1,\cdots,\zb_r \rangle$, es decir, que $\beta_{r+1}=\beta_{r+2}=\cdots = \beta_n=0$.  Volviendo a \eqref{eq:totalsum}, vemos
 que
  $$
  \sum_{i=1}^r\gamma_i \zb_i +\sum_{j=r+1}^{k}\alpha_j \ub_j=\cero,
  $$
  y entonces
  $\gamma_1=\gamma_2=\cdots=\gamma_r=\alpha_{r+1}=\cdots=\alpha_{k}=0$ porque
  $\B$ es base y por lo tanto L.I.

  Hemos probado que
  $$\tilde{\B}=\{\zb_1,\cdots,\zb_r,\ub_{r+1},\cdots, \ub_k, \vb_{r+1},\cdots, \vb_n\}$$
  es una base de $U+V$, por lo tanto
  $$\dim(U+V)=r+(k-r)+(n-r)=k+n-r=\dim(U)+\dim(V)-\dim(U\cap V),$$
  como queríamos probar. \end{proof} 
  
  
\section{Operaciones con matrices}

\subsection{Multiplicación de matrices}

Dadas matrices $A \in \K^{m \times n}$ y $B \in \K^{n \times p}$

$$
\Ab =\begin{pmatrix}a_{11}&a_{12}&\cdots &a_{1n}\\a_{21}&a_{22}&\cdots &a_{2n}\\\vdots &\vdots &\ddots &\vdots \\a_{m1}&a_{m2}&\cdots &a_{mn}\\\end{pmatrix},\quad  {\Bb} ={\begin{pmatrix}b_{11}&b_{12}&\cdots &b_{1p}\\b_{21}&b_{22}&\cdots &b_{2p}\\\vdots &\vdots &\ddots &\vdots \\b_{n1}&b_{n2}&\cdots &b_{np}\\\end{pmatrix}}
$$ el producto $\Cb = \Ab\Bb$ es la matriz de $m$ filas y $p$ columnas

$$
\Cb =\begin{pmatrix}c_{11}&c_{12}&\cdots &c_{1p}\\c_{21}&c_{22}&\cdots &c_{2p}\\\vdots &\vdots &\ddots &\vdots \\c_{m1}&c_{m2}&\cdots &c_{mp}\\\end{pmatrix} \in \K^{m \times p},
$$
con
$$
c_{ij}=a_{i1}b_{1j}+a_{i2}b_{2j}+\cdots +a_{in}b_{nj}=\sum _{k=1}^{n}a_{ik}b_{kj}
$$
(en la casilla $(i,j)$ de $\Cb$ ponemos la suma del producto de las casillas de fila $i$ de $\Ab$ con las casillas de la columna $j$ de $\Bb$) .


Si multiplicamos dos matrices o vectores en \python con $*$ ...

\begin{Shaded}
\begin{lstlisting}[language=Python]
A1 = np.array([[1,2],[3,4]])
A2 = np.array([[1,0],[0,1]])
print(A1)
print(A2)
print(A1 * A2)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% A1 =
%%  [[1 2]
%%  [3 4]]
%% A2 =
%%  [[1 0]
%%  [0 1]]
%% A1 * A2 =
%%  [[1 0]
%%  [0 4]]
\end{verbatim}

La operación $*$ en \python calcula el producto coordenada a coordenada. Esta operación se llama producto de Hadamard, y es útil en muchos casos, pero no es el producto usual de matrices.

Para el producto usual de matrices usamos en Python el símbolo @.

\begin{Shaded}
\begin{lstlisting}[language=Python]
print("A1 @ A2 = \n", A1 @ A2)   # Producto usual de matrices
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% A1 @ A2 =
%%  [[1 2]
%%  [3 4]]
\end{verbatim}

¡Revisar siempre que estemos usando el producto correcto en \python!

\begin{ejercicio} \label{ejer:productos}
Realizar (a mano) los siguientes productos de matrices:
\begin{enumerate}
\item  $\begin{pmatrix}3&5\\ 2 & -9 \end{pmatrix} \cdot \begin{pmatrix}1&-1\\ 0 & 2 \end{pmatrix}$
\item  $\begin{pmatrix}3&5\end{pmatrix} \cdot \begin{pmatrix}4\\ -3\end{pmatrix}$
\item  $\begin{pmatrix}4\\ -3\end{pmatrix} \cdot \begin{pmatrix}3&5\end{pmatrix}$
\item \label{item:sistema}  $\begin{pmatrix}3&5\\ 2 & -9 \end{pmatrix} \cdot \begin{pmatrix}x\\ y \end{pmatrix}$
\end{enumerate}
\end{ejercicio}

\textbf{Observaciones:}

\begin{itemize}
\item El producto de matrices es asociativo. Es decir $\Ab(\Bb\Cb) = (\Ab\Bb)\Cb$, para matrices con los tamaños apropiados para realizar los productos.
\item El producto de matrices no es conmutativo. En general, no vale $\Ab \Bb = \Bb \Ab$, ni siquiera en el caso de matrices cuadradas. Lo verificamos en \python.
\end{itemize}

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1, 2], [2, 3]])
B = np.array([[2, 5], [1, 4]])
print("A @ B = \n", A @ B)
print("B @ A = \n", B @ A)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
A @ B =
 [[ 4 13]
 [ 7 22]]
B @ A =
 [[12 19]
 [ 9 14]]
\end{verbatim}

\begin{itemize}
\item Si bien vimos que el conjunto de matrices $\K^{m \times n}$ es un espacio vectorial, el producto de matrices no es una operación de espacio vectorial.
\end{itemize}

\subsection{Matrices transpuesta y conjugada}

La matriz transpuesta de $\Ab = (a_{ij}) \in {\R^{m \times n}}$ es la matriz que se obtienen a partir de $\Ab$ intercambiando filas por columnas, es decir $\Ab^T = (a_{ji}) \in \R^{n \times m}$.

\begin{ejemplo}\leavevmode
\begin{itemize}
\item Si $\Ab =\begin{pmatrix}a_{11}&a_{12}&a_{13} \\ a_{21}&a_{22}&a_{23}\end{pmatrix}$ , $\Ab^T = \begin{pmatrix}a_{11}&a_{21}\\a_{12} & a_{22} \\ a_{13} & a_{23}\end{pmatrix}$.
\item Si $\Ab =\begin{pmatrix}5&7 \\ 3&-1\end{pmatrix}$ , $\Ab^T = \begin{pmatrix}5&3\\7 & -1 \end{pmatrix}$.
\end{itemize}
\end{ejemplo}

\begin{proposicion}\leavevmode
\begin{itemize}
\item $(\Ab^T)^T = \Ab$.
\item $(\Ab \Bb)^T = \Bb^T \Ab^T$.
\end{itemize}
\end{proposicion}

En \python calculamos la transpuesta de una matriz con el comando \texttt{transpose} de \texttt{numpy}.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[5,7],[3,-1]])
print(np.transpose(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
## [[ 5  3]
##  [ 7 -1]]
\end{verbatim}

En lo que sigue resulta de utilidad definir lo siguiente: consideremos $\vb\in \Kn$, $\Ab\in \Knn$, con $\overline{\vb}\in \Kn$ (resp. $\overline{\Ab}\in \Knn$), denotamos el vector (resp. matrix) que tiene los mismos elementos que $\vb$ (resp. $\Ab$) pero conjugados. Obviamente si $\K=\R$, $\overline{\vb}=\vb$,  $\overline{\Ab}=\Ab$.

La siguiente definición generaliza a la traspuesta en las matrices y a la conjugación en los escalares.

Dada $\Ab\in \K^{n\times m}$, la \emph{matriz conjugada} de $\Ab$, denotada con $\Ab^*$
 se define como $\Ab^*=\overline{\Ab^T}$.

Notar que si $a\in \K^{1\times 1}$ ( o sea, es un escalar, $a\in \K$) entonces $a^*=\overline{a}$. La conjugación hereda las propiedades de la traspuesta:
\begin{itemize}
 \item $(\Ab^*)^*=\Ab$
 \item Si $\K=\R$, $\Ab^*=\Ab^T$.
 \item $(\Ab\Bb)^*=\Bb^*\Ab^*$
 \item $(a\Ab+b\Bb)^*=\overline{a}\Ab^*+ \overline{b}\Bb^*$.
\end{itemize}




\subsection{Sistemas lineales y ecuaciones matriciales}

Observando el producto del punto \ref{item:sistema} del Ejercicio \ref{ejer:productos}, vemos que podemos plantear el sistema de ecuaciones lineales

$$
\left\{ {\begin{alignedat}{5}3x&&\;+\;&&5y&&\;=\;&&4&\\2x&&\;-\;&&9y&&\;=\;&&15&.\end{alignedat}} \right.
$$
en forma matricial
$$\begin{pmatrix}3&5\\ 2 & -9 \end{pmatrix} \cdot \begin{pmatrix}x\\ y \end{pmatrix} = \begin{pmatrix}4\\ 15 \end{pmatrix},$$
o en general, $\Ab \xb = \bb$, donde $\Ab \in \mathbb{R}^{m \times n}$ es la matriz de coeficientes, $\xb$ es un vector o matriz columna de incógnitas y $\bb \in \mathbb{R}^{m}$ es el vector de términos constantes.

\textbf{Pregunta:} ¿cuántas incógnitas y cuántas ecuaciones tiene el sistema $\Ab \xb = \bb$ con los tamaños dados?

Para resolver sistemas de ecuaciones en \python podemos usar el comando \texttt{solve} (vamos a volver a esto más adelante).

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[3,2],[5,-4]])
b = np.array([22, -11])
print(np.linalg.solve(A, b))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
## [3.  6.5]
\end{verbatim}

\subsection{Rango de una matriz}

Para saber si un sistema de ecuaciones puede tener solución única, infinitas soluciones o ninguna solución, calculamos el \emph{rango} de la matriz $A$. Pensando las filas de una matriz como ecuaciones, el rango de la matriz nos indica cuantas ecuaciones "independientes" tenemos.

El rango de una matriz es la máxima cantidad de filas o columnas linealmente independientes que posee la matriz.

\begin{proposicion} La máxima cantidad de filas linealmente independientes de una matriz coincide con la máxima cantidad de columnas linealmente independientes.
\end{proposicion}

Por lo tanto, no es necesario distinguir rango-fila de rango-columna, y hablamos simplemente de \emph{rango}.

\begin{ejemplo}\leavevmode
\begin{enumerate}
\item $\rank\left(\begin{pmatrix}1&4&7\\0&2&6\end{pmatrix}\right) = 2$
\item $\rank\left(\begin{pmatrix}1&0&1 \\ 0&1&2 \\ 1 & 2 & 5\end{pmatrix}\right) = 2$
\end{enumerate}
\end{ejemplo}

\subsubsection{¿Cómo calcular el rango?}

Para calcular el rango de una matriz, triangulamos la matriz y contamos cuántas filas no nulas quedan.

\begin{proposicion}
El espacio vectorial generado por las filas de una matriz antes o después de triangular es el mismo.
\end{proposicion}

En \python, calculamos el rango de una matriz con el comando \texttt{matrix\_rank} de \texttt{numpy.linalg}.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1,0,1],[0,1,2],[1,2,5]])
print("Rango de A = ", np.linalg.matrix_rank(A))

B = np.array([[1,2,3],[4,5,6],[7,8,9]])
print("Rango de B = ", np.linalg.matrix_rank(B))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
## Rango de A =  2
## Rango de B =  2
\end{verbatim}

\subsubsection{Sistemas de ecuaciones y rango de matrices}

Si $\rank(\Ab)$ es igual a la cantidad de filas, el sistema $\Ab \xb = \bb$ siempre tiene solución. Todas las ecuaciones son independientes entre sí.

Si la matriz $\Ab$ es cuadrada y $\rank(\Ab)$ es igual a la cantidad de filas, decimos que $\Ab$ tiene rango máximo. En este caso, el sistema $\Ab \xb = \bb$ tiene solución única para todo $\bb$.

\subsubsection{Rango de un producto de matrices}

Dadas matrices $\Ab \in \mathbb{R}^{m \times n}$ y $\Bb \in \mathbb{R}^{n \times p}$,

\begin{enumerate}
\item  $\rank(\Ab) = \rank(\Ab^T) = \rank(\Ab^T\Ab) = \rank(\Ab\Ab^T)$
\item  $\rank(\Ab \Bb) \le \min\{\rank(\Ab), \rank(\Bb)\}$.
\item  Si $\rank(\Bb) = n$, entonces $\rank(\Ab \Bb) = \rank(\Ab)$.
\item  Si $\Bb \in \R^{n \times n}$, y $\Bb$ tiene rango máximo, entonces $\rank(\Ab \Bb) = \rank(\Ab)$.
\end{enumerate}

Idea de las demostración: las filas de $\Ab \Bb$ son combinaciones de las filas de $\Bb$ y las columnas de $\Ab\Bb$ son combinaciones de las columnas de $\Ab$.


\subsection{Matrices especiales}

\subsubsection{Matriz diagonal}

Una matriz $\Ab \in \R^{n \times n}$ se dice diagonal si $a_{ij} = 0$ para todo $i \neq j$, es decir:

$$
\Ab =\begin{pmatrix}a_{11}&0&\cdots &0\\0&a_{22}&\cdots &0\\\vdots &\vdots &\ddots &\vdots \\0&0&\cdots &a_{nn}\\\end{pmatrix}
$$

\begin{ejercicio} Calcular a mano pero sin hacer muchas cuentas:
\begin{enumerate}
\item   $\begin{pmatrix}1&0&0 \\ 0&2&0 \\ 0& 0 & 3\end{pmatrix}^3$,
\item   $\begin{pmatrix}1&0&0 \\ 0&2&0 \\ 0& 0 & 3\end{pmatrix} \cdot \begin{pmatrix}1&1&1 \\ 2&2&2 \\ 3& 3 & 3\end{pmatrix}$,
\item   $\begin{pmatrix}1&1&1 \\ 2&2&2 \\ 3& 3 & 3\end{pmatrix} \cdot \begin{pmatrix}1&0&0 \\ 0&2&0 \\ 0& 0 & 3\end{pmatrix}$.
\end{enumerate}
\end{ejercicio}

\begin{Shaded}
\begin{lstlisting}[language=Python]
# Usamos el comando diag para definir matrices diagonales
D = np.diag(np.array([1,2,3]))
print("D = \n", D)
print("D^2 = \n", D @ D)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% D =
%%  [[1 0 0]
%%  [0 2 0]
%%  [0 0 3]]
%% D^2 =
%%  [[1 0 0]
%%  [0 4 0]
%%  [0 0 9]]
\end{verbatim}

\subsubsection{Matriz identidad}

Para cada $n \in \mathbb{N}$, la matriz $I_n \in \R^{n \times n}$ es la matriz diagonal con $a_{ii} = 1$ para todo $1 \le i \le n$ y $a_{ij} = 0$ para $i \ne j$, es decir:
$$
I_n =\begin{pmatrix}1&0&\cdots &0\\0&1&\cdots &0\\\vdots &\vdots &\ddots &\vdots \\0&0&\cdots &1\\\end{pmatrix}
$$

\begin{proposicion}
Para toda $\Bb \in \R^{n \times n}$ , $I_n \cdot \Bb = \Bb \cdot I_n = \Bb$.
\end{proposicion}

Podemos usar el comando \texttt{eye} de \texttt{numpy} para definir una matriz identidad.

\begin{Shaded}
\begin{lstlisting}[language=Python]
id = np.eye(3)

# Creamos una matriz de 3 x 3 con números aleatorios entre 0 y 1
A = np.random.rand(3,3)
print("A = \n", A)
print("id * A = \n", id @ A)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% A =
%%  [[0.91836939 0.31101594 0.48474114]
%%  [0.00093026 0.37622722 0.91214465]
%%  [0.6293026  0.20801675 0.6855896 ]]
%% id * A =
%%  [[0.91836939 0.31101594 0.48474114]
%%  [0.00093026 0.37622722 0.91214465]
%%  [0.6293026  0.20801675 0.6855896 ]]
\end{verbatim}

\subsubsection{Más Matrices especiales}

\begin{itemize}
\item \textbf{Triangular superior:} Una matriz $\Ub \in \R^{n \times n}$ se llama triangular superior si $a_{ij} = 0$ para todo $i > j$ (es decir, todas las entradas abajo de la diagonal son 0).
\item \textbf{Triangular inferior:} Una matriz $\Lb \in \R^{n \times n}$ se llama triangular inferior si $a_{ij} = 0$ para todo $i > j$ (es decir, todas las entradas arriba de la diagonal son 0).
\item \textbf{Matriz simétrica:} $\Ab\in \R^{n\times n}$ es simétrica si $\Ab^T = \Ab$.
\item \textbf{Matriz Hermitiana:} $\Ab\in \C^{n\times n}$ es Hermitiana si $\Ab^* = \Ab$.
\item \textbf{Matriz ortogonal:} $\Ab$ es ortogonal si $\Ab\Ab^T = \Ab^T\Ab = \Id_n$.
\item \textbf{Matriz unitaria:} $\Ab\in \C^{n\times n}$ es unitaria si $\Ab\Ab^* = \Ab^*\Ab = \Id_n$.
\end{itemize}

    \subsubsection{Inversa de una matriz}

Dada una matriz $\Ab \in \K^{n \times n}$, si existe una matriz $\Bb \in \K^{n\times n}$ tal que
$$
\Ab\Bb = \Id_n = \Bb\Ab,
$$
decimos que $\Ab$ es inversible y $\Bb$ es la inversa de $\Ab$. Si $\Ab$ es inversible, la inversa es única y la notamos $\Ab^{-1}$. Si $\Ab$ no es inversible, decimos que $\Ab$ es singular.

Para calcular la inversa de una matriz podemos aplicar eliminación gaussiana, observando que encontrar una matriz $B$ tal que $\Ab \Bb = \Id_n$ es equivalente a resolver los $n$ sistemas de ecuaciones
$$
\Ab \begin{pmatrix} b_{1j} \\ b_{2j} \\ \vdots \\ b_{nj} \end{pmatrix} = \eb_j,
$$
donde $\eb_j$ es el $j$-ésimo vector canónico, que coinicide con la $j$-ésima columna de la matriz $\Id_n$.

\begin{ejemplo}
Calculamos la inversa de la matriz
$$
\Ab = \begin{pmatrix} 2 & 0 & -2 \\ 1 & -1 & 1 \\ 0 & 2 & 1\end{pmatrix}.
$$
Podemos resolver los sistemas $\Ab \bb_j = \eb_j$, $1 \le j \le 3$, simultáneamente considerando una matriz ampliada con los 3 vectores $\eb_j$ a la derecha:
$$
\left(\begin{array}{ccc|ccc} 2 & 0 & -2 & 1 & 0 & 0 \\ 1 & -1 & 1 & 0 & 1 & 0\\ 0 & 2 & 1 & 0 & 0 & 1\end{array}\right).
$$

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1, 4, 3, -1,], [1, 0, 1, 0], [3, 3, 2, 7], [2, 6, 0, 14], [2, 3, 1, 7]])
print(row_echelon(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[ 2.  0. -2.  1.  0.  0.]
%%  [ 1. -1.  1.  0.  1.  0.]
%%  [ 0.  2.  1.  0.  0.  1.]]
%% Matriz escalonada:
%%  [[ 1.   0.  -1.   0.5  0.   0. ]
%%  [ 0.   1.  -2.   0.5 -1.  -0. ]
%%  [ 0.   0.   1.  -0.2  0.4  0.2]]
\end{verbatim}

La función \texttt{row\_echelon} que estamos utilizando coloca 1's como primer elemento no nulo de cada fila, dividiendo cada fila por el escalar apropiado.

A partir de la matriz escalonada podemos ahora encontrar fácilmente las casillas $b_{ij}$ de $\Bb$. Por ejemplo, la última fila será $[-0.2 0.4 0.2]$. Para las filas anteriores, podemos realizar ahora la triangulación hacia arriba:
$$
\left(\begin{array}{ccc|ccc}
 1. &  0. & -1. &  0.5 &  0.  &  0.  \\
 0. &  1. & -2. &  0.5 & -1.  & 0.  \\
 0. &  0. &  1. & -0.2 &  0.4 &  0.2 \\
\end{array}\right)
\xrightarrow{\substack{f_2 + 2f_3 \rightarrow f_2 \\ f_1 + f_3 \rightarrow f_1}}
\left(\begin{array}{ccc|ccc}
 1. &  0. & 0. &  0.5 &  0.4  &  0.2  \\
 0. &  1. & 0. &  0.5 & 0.2  & 0.4.  \\
 0. &  0. &  1. & -0.2 &  0.4 &  0.2 \\
 \end{array}\right).
$$

Ahora la matriz que estamos buscando es exactamente la matriz formada por las últimas 3 columnas de la matriz ampliada.
$$
\Bb = \begin{pmatrix}
 0.3 &  0.4  &  0.2  \\
 0.1 & 0.2  & 0.4.  \\
 -0.2 &  0.4 &  0.2 \\
\end{pmatrix}.
$$

Lo verificamos en \python.

\begin{Shaded}
\begin{lstlisting}[language=Python]
B = np.array([[0.3, 0.4, 0.2], [0.1, -0.2, 0.4], [-0.2, 0.4, 0.2]])
print(A @ B)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[ 1.00000000e+00  0.00000000e+00  0.00000000e+00]
%%  [-2.77555756e-17  1.00000000e+00  0.00000000e+00]
%%  [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]
\end{verbatim}

\end{ejemplo}

\begin{aplicacion}
Si $\Ab \in \R^{n \times n}$ es inversible, la solución del sistema
$$
\Ab\xb = \bb
$$
es $\xb = \Ab^{-1}\bb$.
\end{aplicacion}

Para calcular la inversa en \python usamos el comando \texttt{inv} del paquete \texttt{numpy.linalg} (o podemos usar el comando \texttt{solve} del mismo paquete para resolver la ecuación matricial $\Ab\Xb = \Id_n$).

\begin{Shaded}
\begin{lstlisting}[language=Python]
# Probando...
A = np.array([[1,7],[2,3]])
print("A = \n", A)

A_inv = np.linalg.inv(A)
print("A^(-1) = \n", A_inv)

print("A * A^(-1) = \n", A @ A_inv)

print("La solución de AX = Id_2 es")
print(np.linalg.solve(A, np.eye(2)))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
## A =
##  [[1 7]
##  [2 3]]
## A^(-1) =
##  [[-0.27272727  0.63636364]
##  [ 0.18181818 -0.09090909]]
## A * A^(-1) =
##  [[1. 0.]
##  [0. 1.]]
## La solución de AX = Id_2 es
##  [[-0.27272727  0.63636364]
##  [ 0.18181818 -0.09090909]]
\end{verbatim}
\textbf{Nota:} En la práctica, es mejor resolver un sistema por eliminación gaussiana que invirtiendo la matriz.

\subsubsection{Traza de una matriz}

La traza de una matriz \emph{cuadrada} es la suma de los elementos de la diagonal.

Si $\Ab = (a_{ij}) \in \R^{n \times n}$, $\tr(\Ab) = a_{11} + a_{22} + \dots + a_{nn} = \sum_{i=1}^n a_{ii}$ .

\begin{proposicion} Si $\Ab, \Bb \in \R^{n \times n}$:
\begin{itemize}
\item $\tr(\Ab^T)=\tr(\Ab)$
\item $\tr(\Ab+\Bb) = \tr(\Ab) + \tr(\Bb)$.
\end{itemize}
\end{proposicion}

Calculamos la traza en \python con el comando \texttt{trace} de \texttt{numpy}.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[1,5,1],[-6,7,8],[0,9,-2]])
print("A = \n", A)
print("Traza de A = ", tr(A)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% A =
%%  [[ 1  5  1]
%%  [-6  7  8]
%%  [ 0  9 -2]]
%% Traza de A =  6
\end{verbatim}

\subsection{Determinante de una matriz}

El determinante de una matriz \emph{cuadrada} se puede definir recursivamente por la siguiente fórmula

$$
\det(\Ab)= \begin{cases}
a_{11} & \text{si } n = 1 \\
\sum _{j=1}^{n}(-1)^{i+j}a_{ij} \det(\Mb_{ij}) & \text{si } n > 1,
\end{cases}
$$
donde $\Mb_{ij}$ es la matrix de $(n-1) \times (n-1)$ que se obtiene al eliminar la fila $i$ y la columna $j$ de $\Ab$.

\begin{ejemplo}\leavevmode
\begin{enumerate}
\item $\det\begin{pmatrix} a & b \\ c & d \end{pmatrix} = ad - bc$
\item $\det\begin{pmatrix} 1 & 2 & 3 \\ 3 & 0 & 7 \\ 0 & -1 & 4 \end{pmatrix} = \det\begin{pmatrix} 0 & 7 \\ -1 & 4 \end{pmatrix} - 3 \det\begin{pmatrix} 2 & 3 \\ -1 & 4 \end{pmatrix} = 7 - 3 \cdot 11=-26$
\end{enumerate}
\end{ejemplo}

\begin{proposicion} Si $\Ab \in  \R^{n \times n}$ y $f_i$, $1 \le i \le n$, son las filas de $\Ab$, las siguientes operaciones en la matriz modifican el determinante:
\begin{itemize}
\item transponer la matriz: $\det(\Ab^T) = \det(\Ab)$
\item multiplicar una fila por un escalar: $\det\begin{pmatrix} \text{---} & f_1 & \text{---}\\ & \vdots & \\ \text{---} & f_{i-1} & \text{---}\\ \text{---} & \alpha f_i & \text{---}\\ \text{---} & f_{i+1} & \text{---} \\ & \vdots & \\ \text{---} & f_n  & \text{---}\end{pmatrix} = \alpha \det(A)$
\item sumar un múltiplo de una fila a otra fila: $\det\begin{pmatrix} \text{---} & f_1 & \text{---}\\ & \vdots & \\ \text{---} & f_{i-1} & \text{---}\\ \text{---} & f_i + \beta f_j & \text{---}\\ \text{---} & f_{i+1} & \text{---} \\ & \vdots & \\ \text{---} & f_n  & \text{---}\end{pmatrix} = \det(A)$
\item intercambiar dos filas: $\det\begin{pmatrix} \text{---} & f_1   & \text{---}\\ & \vdots   & \\ \text{---} & f_{i}   & \text{---}\\ & \vdots & \\ \text{---} & f_{j}   & \text{---}\\  & \vdots   & \\ \text{---} & f_n   & \text{---} \end{pmatrix} = - \det\begin{pmatrix} \text{---} & f_1   & \text{---}\\ & \vdots   & \\ \text{---} & f_{j}   & \text{---}\\ & \vdots & \\ \text{---} & f_{i}   & \text{---}\\  & \vdots   & \\ \text{---} & f_n   & \text{---} \end{pmatrix}$
\item multiplicar toda la matriz por un escalar: $\det(k\Ab)=k^n \det(\Ab)$, para $k \in \R$.
\item multiplicar toda la matriz por $(-1)$: $\det(-\Ab)=(-1)^n \det(\Ab)$.
\end{itemize}
\end{proposicion}

En base a esta propiedad podemos demostrar f\'acilmente las siguientes propiedades.

\begin{corolario}\leavevmode
\begin{itemize}
\item Si $\Ab$ tiene dos filas iguales, $\det(\Ab)= 0$.
\item Si $\Ab$ tiene una fila de ceros, $\det(\Ab)= 0$.
\item $\det(\Ab) = 0$ si y solo si $\Ab$ es singular.
\end{itemize}
\end{corolario}

\begin{proposicion}
Si $\Ab, \Bb \in \R^{n \times n}$,
$$\det(\Ab \Bb) = \det(\Ab)\det(\Bb).$$
\end{proposicion}

Calculamos determinantes en \python con el comando \texttt{det} de \texttt{numpy.linalg}.
\begin{Shaded}
\begin{lstlisting}[language=python]
A = np.array([[1,5,0],[-1,-3,8],[0,1,-2]])
B = np.array([[0,4,2],[2,6,1],[1,5,-1]])
print("det(A) = ", np.linalg.det(A));
print("det(B) = ", np.linalg.det(B));
print("det(AB) = ", np.linalg.det(A @ B));

# No hay relación con los determinantes de A y B
print("det(A + B) = ", np.linalg.det(A + B));

M = np.array([[1,2,3],[4,5,6],[7,8,9]])
print("det(M) = ", np.linalg.det(M));
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% det(A) =  -12.0
%% det(B) =  19.999999999999996
%% det(AB) =  -240.0000000000002
%% det(A + B) =  51.0
%% det(M) =  -9.51619735392994e-16
\end{verbatim}

\begin{ejercicio}
Para $\Ab = \begin{pmatrix} 3 & 2 & -1 \\ 3 & 0 & 7 \\ 0 & -1 & 4 \end{pmatrix}$ , probar que el sistema $\Ab\xb = \bb$ tiene solución única para todo $\bb \in \R^3$
\end{ejercicio}

\subsubsection{Determinante de una matriz triangular superior o inferior}

Si $\Ab \in \R^{n \times n}$ es triangular inferior o superior su determinante es igual al producto de los elementos de la diagonal.

$$
\det\begin{pmatrix}a_{11}&a_{12}&\cdots & a_{1n} \\ 0 &a_{22}&\cdots & a_{2n}\\\vdots &\vdots &\ddots &\vdots \\0&0 & \cdots &a_{nn}\\\end{pmatrix} = \det\begin{pmatrix}a_{11}& 0&\cdots &0 \\ a_{21} &a_{22}&\cdots & 0\\\vdots &\vdots &\ddots &\vdots \\a_{n1}&a_{n2} & \cdots &a_{nn}\\\end{pmatrix} = \prod_{i=1}^n a_{ii}
$$




\section{Cambio de base}

Dado un espacio vectorial $V$ de dimensión $n$ llamamos base canónica de $V$ al conjunto $\E= \{\eb_1, \dots, \eb_n\}$ de vectores canónicos, $\eb_i(j) = \begin{cases} 1 & \text{ si } i = j \\ 0 & \text{ si } i \neq j \end{cases}$, donde $\eb_i(j)$ es la $j$-ésima coordenada del vector $\eb_i$.

Dada otra base $\B$ de $V$, queremos saber cómo escribir en la base $\B$ a un vector $\vb$ del cual conocemos sus coordenadas en la base $\E$. Y viceversa, cómo escribir en la base canónica a un vector del cual conocemos sus coordenadas en la base $\B$.

\subsection{Cambio de base de $\B$ a $\E$}

Analizamos un ejemplo. Consideramos la base de $\R^3$
$$\B= \{(1,2,5), (0, 1, 7), (0,0,-1)\}$$  y el vector
$$\vb = (3, -2, 1)_\B.$$

Para averiguar las coordenadas de $\vb$ en la base canónica, hacemos la cuenta
$$\vb = 3 (1,2,5) + (-2) (0, 1, 7) + 1 (0, 0, -1) = (3, 4, 0)$$
(en general omitimos el subíndice $\E$ cuando escribimos un vector en las coordenadas de la base canónica).

Podemos escribirlo matricialmente:
$$
\vb = \begin{pmatrix}
1 & 0 & 0 \\
2 & 1 & 0 \\
5 & 7 & -1\end{pmatrix} \begin{pmatrix} 3 \\ -2 \\ -1 \end{pmatrix} =  \begin{pmatrix} 3 \\ 4 \\ 0 \end{pmatrix}.
$$
Observamos que la matriz $\begin{pmatrix} 1 & 0 & 0 \\ 2 & 1 & 0 \\ 5 & 7 & -1 \end{pmatrix}$ posee los vectores de $\B$ como columnas y es la matriz que nos permite pasar un vector en coordenadas de una base $\B$ a la base canónica. Llamamos $\Cb_{\B\E}$ a esta matriz. Obtenemos
$$
\vb_\E= \Cb_{\B\E} \vb_\B.
$$

\begin{ejercicio}\leavevmode
\begin{enumerate}
 \item Dada la base $\B = \{(1,3,7), (4, 0, 1), (5, -7, 0)\}$ de $\R^3$ y el vector $\vb$ de $\R^3$ de coordenadas $(1,2,-5)$ en la base $\B$, hallar las coordenadas de $\vb$ en la base canónica.
\item Dada la base $\B = \{1, (x-1), (x-1)^2\}$ de $\R[x]_2$ y el polinomio $p(x)$ de coordenadas $(7, -2, 1)$ en la base $\B$, hallar las coordenadas de $p$ en la base canónica de $\R[x]_2$. Observar que esto equivale a escribir como suma de potencias de $x$ a un polinomio que viene dado como suma de potencias de $(x-1)$.
\end{enumerate}
\end{ejercicio}

\subsection{Cambio de base de $\B$ a $\E$}

Ahora queremos escribir a $\vb = (3,7, -1)_\E$ en la base $\B$. Para esto, necesitamos resolver el sistema de ecuaciones $$
(3, 7, -1) = \sum_{i=1}^{3} a_i b_i = a_1 (1,2,5) + a_2 (0, 1, 7) + a_3 (0,0,-1)
$$ Esto nos da un sistema de 3 ecuaciones y 3 incógnitas, que podemos plantear en forma matricial:
$$
\begin{pmatrix}
1 & 0 & 0 \\
2 & 1 & 0 \\
5 & 7 & -1
\end{pmatrix} \begin{pmatrix} a_1 \\ a_2 \\a_3 \end{pmatrix}  = \begin{pmatrix} 3 \\ 7 \\ -1 \end{pmatrix}.
$$

Observamos que la matriz $\begin{pmatrix} 1 & 0 & 0 \\ 2 & 1 & 0 \\ 5 & 7 & -1 \end{pmatrix}$ de coeficientes posee los vectores de $\B$ como columnas, es decir, es la matriz $\Cb_{\B\E}$. Como $\B$ es una base, la matriz $\Cb_{\B\E}$ es inversible (¿por qué?).

Por lo tanto,
$$
 \begin{pmatrix} a_1 \\ a_2 \\a_3 \end{pmatrix}  = \begin{pmatrix}
1 & 0 & 0 \\
2 & 1 & 0 \\
5 & 7 & -1
\end{pmatrix}^{-1} \begin{pmatrix} 3 \\ 7 \\ -1 \end{pmatrix} = (\Cb_{\B\E})^{-1} \begin{pmatrix} 3 \\ 7 \\ -1 \end{pmatrix}.
$$

Obtenemos que la matriz de cambio de base de la base canónica $\E$ a una base $\B$ es $\Cb_{\E\B} = \Cb_{\B\E}$.

%```{r}
%C_BE = matrix(c(1,0,0,2,1,0,5,7,-1), nrow = 3, byrow=TRUE)
%C_EB = solve(C_BE)
%\vb = c(3,7,-1)
%\vb_B = C_EB %*% \vb   # El vector en la base B
%print(\vb_B)
%
%# Podemos convertir nuevamente a la base canónica
%print(C_BE %*% \vb_B)
%
%```

{\bf En resumen:}
Tenemos una base $\B=\{b_1, \dots, b_n\}$ de un espacio vectorial $V$ de dimensión $n$.

\begin{enumerate}
\item Construimos la matriz $\Cb_{\B\E} = \begin{pmatrix} \mid & \mid & & \mid \\ {\bb}_{1} & {\bb}_{2} & \cdots & {\bb}_{n}\\ \mid & \mid & & \mid \\ \end{pmatrix}$.
\item Para pasar un vector en base $\B$ a base canónica, usamos $\vb_\E= \Cb_{\B\E} \vb_\B$.
\item Para pasar un vector en base base canónica a la base $\B$, definimos $\Cb_{\E\B} = (\Cb_{\B\E})^{-1}$ y usamos $\vb_\B= \Cb_{\E\B} \vb_\E$.
\end{enumerate}   

\section{Transformaciones lineales}

\subsection{Matrices y transformaciones lineales}

Una matriz $\Ab \in \R^{m \times n}$ define una funci\'on $T_{\Ab}: \mathbb{R}^n \rightarrow \mathbb{R}^m$ dada por
$$
T_{\Ab}(\vb) = \Ab\vb.
$$
(tomando a $\vb$ como matriz columna).

\begin{ejemplo}
Si $\Ab = \begin{pmatrix} 1 & 3 & 0 \\ 2 & -1 & -4\end{pmatrix} \in \mathbb{R}^{2 \times 3}$ y $\vb = (1, 0, -2)$, entonces $$
T_{\Ab}(\vb) = \begin{pmatrix} 1 & 3 & 0 \\ 2 & -1 & -4\end{pmatrix} \begin{pmatrix} 1 \\ 0 \\ -2\end{pmatrix} = \begin{pmatrix} 1 \\ 10 \end{pmatrix}
$$

Si multiplicamos la matriz $\Ab$ por un vector genérico $\vb = (x_1, x_2, x_3) \in \R^3$, obtenemos
$$
T_{\Ab}(\vb) = \begin{pmatrix} 1 & 3 & 0 \\ 2 & -1 & -4\end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3\end{pmatrix} = \begin{pmatrix} 1 x_1 + 3 x_2 + 0x_3 \\ 2 x_1 - x_2 - 4x_3 \end{pmatrix}.
$$

Entonces podemos escribir $$
T_{\Ab}(x_1, x_2, x_3) = (x_1 + 3x_2, 2x_1-x_2 - 4x_3).
$$
\end{ejemplo}

\textbf{Ejercicio.} Escribir a la función $f(x_1, x_2) = (3x_1, x_2 - x_1, x_2 + 2x_1)$ de $\R^2$ en $\R^3$ en forma matricial.

Estas funciones reciben el nombre de \emph{transformaciones lineales}.

\begin{definicion}
Dados dos espacios vectoriales $V$ y $W$, una función $f: V \rightarrow W$ se llama \textbf{transformación lineal} si cumple:
\begin{enumerate}
\item  $f(\vb + \vb')= f(\vb) + f(\vb')$ para todos $\vb, \vb' \in V$.
\item  $f(a \cdot \vb) = a \cdot f(\vb)$ para todos $a \in \R$ y $\vb \in V$.
\end{enumerate}
\end{definicion}

El producto de matrices verifica $\Ab(\vb+\wb) = \Ab\vb + \Ab\wb$ y $\Ab(a\vb) = a(\Ab\vb)$, por lo tanto se cumplen los axiomas de transformación lineal.

\begin{ejemplo}
La función $f(x_1, x_2) = (3x_1 + 1, x_2 - x_1, x_2 + 3x_1)$ \textbf{no} es una transformación lineal de $\R^2$ en $\R^3$.\
Por ejemplo, $f(2 \cdot (1,1)) = f(2,2) = (7, 0, 8)$ y $2f(1,1) = 2(4, 0, 4)= (8,0,8)$.
\end{ejemplo}

\textbf{Observación.} Las columnas de $\Ab$ son las imágenes de los vectores canónicos $\eb_i$, $1 \le i \le n$.

\begin{proposicion} Si $\B = \{\vb_1, \dots, \vb_n\}$ es una base de $V$, podemos definir una transformación lineal definiendo la imagen de cada elemento de la base.
\end{proposicion}

Para un elemento $\vb \in V$, si $\vb = a_1 \vb_1 + \dots + a_n \vb_n$, entonces $f(\vb) = a_1 f(\vb_1) + \dots + a_n f(\vb_n)$.

\begin{ejemplo} $\B = \{(1,2), (2, -1)\}$ es una base de $\R^2$. Si $f: \R^2 \rightarrow \R^2$ es una transformación lineal, $f(1,2) = (0, 1)$ y $f(2, -1) = (1,3)$, entonces
$$f(3, 1) = f((1,2) + (2, -1)) = f(1,2) + f(2, -1)= (0,1) + (1,3) = (1, 4).$$
\end{ejemplo}

\subsection{Imagen y núcleo de matrices y transformaciones lineales}

En base a esto, hacemos las siguientes definiciones

\begin{definicion}
El subespacio de $\K^m$
$$
\im(A) =\{\bb \in \K^m : \bb = \Ab \xb \text{ para algún } \xb \in \K^n\}
$$
es la imagen de $\Ab$ (o rango de $\Ab$, pero trae confusión con el rango que ya definimos). La imagen de una matriz $\Ab$ está generada por las columnas de $\Ab$ (¿por qué?).

El subespacio de $\K^n$
$$
\ker(\Ab)=\{\xb \in \K^n: \Ab\xb = \cero\}
$$
es el núcleo o kernel de $\Ab$. Podemos calcular el núcleo de $\Ab$ resolviendo el sistema homogéneo $\Ab\xb = \cero$.
\end{definicion}



\textbf{Propiedad.} $\rank(\Ab) = \dim(\im(\Ab))$.

\begin{teorema}[Teorema de la dimensión.] Dada una matriz $\Ab \in \K^{m \times n}$,
$$
n = \dim(\ker(\Ab)) + \dim(\im(\Ab))
$$
\end{teorema}

\begin{proof}
Utilizamos la Proposición \ref{prop:extension} de extensión de bases. Suponemos que el núcleo de $\Ab$ tiene dimensión $t$ y consideramos una base $\{\ub_1, \dots, \ub_t\} \subset \K^n$ del núcleo de $\Ab$. Extendemos dicha base a una base de $\R^n$:
$$
\B = \{\ub_1, \dots, \ub_t, \wb_1, \dots, \wb_{n-t}\}.
$$
Veamos que
$$
\{\Ab \wb_1, \dots, \Ab \wb_{n-t}\}
$$
forman una base de $\im(A)$.

Dado un vector $v \in \R^n$, podemos escribirlo como combinación de elementos de la base:
$$
v = a_1 \ub_1 + \dots +a_t \ub_t  + b_1 \wb_1 + \dots + b_{n-t} \wb_{n-t}.
$$

Como $\Ab \ub_i = \cero$ para $1 \le i \le t$, obtenemos que
$$
\Ab\vb = + b_1 \Ab \wb_1 + \dots + b_{n-t} \Ab\wb_{n-t},
$$
y por lo tanto $\{\Ab \wb_1, \dots, \Ab \wb_{n-t}\}$ es un conjunto de generadores de $\im(A)$. Solo falta ver que es un conjunto linealmente independiente.

Supongamos $c_1 \Ab \wb_1 + \dots + c_{n-t} \Ab \wb_{n-t} = 0$. Luego
$$
\Ab (c_1 \wb_1 + \dots + c_{n-t} \wb_{n-t}) = 0,
$$
es decir $c_1 \wb_1 + \dots + c_{n-t} \wb_{n-t} \in \ker(A)$.

Por lo tanto, existen $d_i$, $1 \le i \le t$ tales que
$$
c_1 \wb_1 + \dots + c_{n-t} \wb_{n-t} = d_1 \ub_1  + \dots + d_t \ub_t.
$$
Pero los vectores de $\B$ forman una base de $\R^n$, por lo tanto debe ser $c_i=0$ para todo $1 \le i \le n-t$, y concluimos que los vectores $\Ab \wb_1, \dots, \Ab \wb_{n-t}$ son linealmente independientes.
\end{proof}


\begin{ejemplo} Dada la matriz $\Ab = \begin{pmatrix} 1 & 0 & -2 & 1 \\ 0 & 2 & -1 & -2 \\ 2 & 1 & 1 & 1 \end{pmatrix}$,
\begin{enumerate}
\item los conjuntos $\im(\Ab)$ y $\ker(\Ab)$, ¿son subespacios de qué espacios vectoriales?
\item hallar generadores de $\im(\Ab)$ y calcular $\dim(\im(\Ab))$.
\item hallar generadores de $\ker(\Ab)$ y calcular $\dim(\ker(\Ab))$.
\item verificar si se cumple el teorema de la dimensión.
\end{enumerate}

\textbf{Respuestas}
\begin{enumerate}
\item   $\im(\Ab) \subset \R^3$ y $\ker(\Ab) \subset \R^4$.
\item   $\im(\Ab) = \langle (1,0,2), (0, 2, 1), (-2, -1, 1), (1, -2, 1)\rangle$. Para calcular la dimensión, triangulamos.

\begin{Shaded}
\begin{lstlisting}[language=python]
A = np.array([[1, 0, -2, 1], [0, 2, -1, -2], [2, 1, 1, 1]])
At = np.transpose(A)
print(At)

At_echelon = row_echelon(At)
print("Matriz A transpuesta escalonada:\n", At_echelon)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[ 1  0  2]
%%  [ 0  2  1]
%%  [-2 -1  1]
%%  [ 1 -2  1]]
%% Matriz A transpuesta escalonada:
%%  [[1.  0.  2. ]
%%  [0.  1.  0.5]
%%  [0.  0.  1. ]
%%  [0.  0.  0. ]]
\end{verbatim}

Obtenemos que $\dim(\im(\Ab)) = 3$, porque quedan 3 filas no nulas.

\item Para resolver el sistema $\Ab\xb = 0$, triangulamos $\Ab$:


\begin{Shaded}
\begin{lstlisting}[language=python]
A = np.array([[1, 0, -2, 1], [0, 2, -1, -2], [2, 1, 1, 1]])
A_echelon = row_echelon(A)
print("Matriz A escalonada:\n", A_echelon)
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
Matriz A escalonada:
 [[ 1.   0.  -2.   1. ]
 [ 0.   1.  -0.5 -1. ]
 [ 0.   0.   1.   0. ]]
\end{verbatim}



Obtenemos $x_3 = 0$, $x_2 - x_4 = 0$ y $x_1 + x_4=0$. Podemos despejar todas las variables $x_1$, $x_2$ y $x_3$ en función de $x_4$:
\begin{align*}
x_1 &= -x_4 \\
x_2 &= x_4  \\
x_3 &= 0   \\
\end{align*}

Luego, las soluciones del sistema son $\{(-x_4, x_4, 0, x_4): x_4 \in \R\} = \{x_4(-1, 1, 0, 1): x_4 \in \R\}$. Obtenemos $$
\ker(\Ab) = \langle (-1, 1, 0, 1) \rangle
$$ y $\dim(\ker(A)) = 1$.

En \python podemos calcular una base del núcleo de una matriz con el comando \texttt{null\_space} del paquete \texttt{scipy.linalg}. Para calcular una solución particular usamos eliminación gaussiana.

\item Tenemos $\dim(\ker(\Ab)) + \dim(\im(\Ab)) = 1 + 3 = 4$, se cumple el teorema.

\end{enumerate}

\end{ejemplo}




\section{Espacios afines}

Dada $\Ab \in \K^{m \times n}$, ya vimos que las soluciones de un sistema
homogéneo de ecuaciones

$$
\Ab\xb = 0
$$

forman un subespacio de $\K^n$. Veamos qué pasa para un sistema
no-homogéneo

$$
\Ab\xb = \bb, \text{ con } \bb \in \K^n.
$$

\begin{ejemplo} Resolvemos el siguiente sistema de ecuaciones:

$$
\left\{\begin{aligned}
5x_1 + 3x_2 &= 11 \\
15x_1 + 9x_2 &= 33 \\
20x_1 + 12x_2 &= 44
\end{aligned}\right.
$$

Construimos la matriz ampliada

$$
\left(\begin{array}{rr|r}5&3&11\\15&9&33\\20&12&44\end{array}\right)
$$

y escalonamos usando \python.

\begin{Shaded}
\begin{lstlisting}[language=Python]
A = np.array([[5,3,11],[15,9,33],[20,12,44]])
print(row_echelon(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% [[1.  0.6 2.2]
%%  [0.  0.  0. ]
%%  [0.  0.  0. ]]
\end{verbatim}
Vemos que se eliminaron las últimas dos ecuaciones, y nos queda solo una
ecuación:
$$
x_1 + 0.6 x_2 = 2.2
$$
de donde podemos despejar $x_1 = 2.2 - 0.6x_2$.

Podemos entonces escribir el conjunto de soluciones en función de $x_2$:
\begin{align*}
S &= \{(2.2 - 0.6 x_2, x_2) : x_2 \in \R\} \\
&= \{(2.2, 0) + (-0.6 x_2, x_2) : x_2 \in \R\} \\
&= \{(2.2, 0) + (-0.6, 1) x_2 : x_2 \in \R\}
\end{align*}

Esto no es un subespacio de $\R^2$ (por ejemplo, $(0,0) \not\in S$),
pero es un subespacio ``corrido'': el conjunto

$$
 \{(-0.6, 1) x_2 : x_2 \in \R\} = \langle (-0.6, 1) \rangle,
$$

es un subespacio de $\R^2$ y los puntos de $S$ se obtienen sumandole el
vector $(2.2, 0)$ a cualquier punto de $\langle (-0.6, 1)\rangle$, es
decir,

$$
S = (2.2, 0) + \langle (-0.6, 1) \rangle
$$

\end{ejemplo}

Estos conjuntos se llaman \textbf{espacios lineales afines}, se obtienen
trasladando un subespacio vectorial en la dirección de un vector del
espacio. El espacio vectorial podría estar generado por varios vectores,
es decir, puede tener cualquier dimensión.

Observamos:

\begin{itemize}
\item   $(2.2, 0)$ es una solución del sistema no-homogéneo $\Ab\xb = \bb$.
\item   El subespacio $\langle (-0.6, 1) \rangle$ es el conjunto de
    soluciones del sistema homogéneo $\Ab\xb = 0$.
\end{itemize}
y esto vale en general:

\begin{proposicion}
Dado el sistema $\Ab\xb = \bb$, si $\tilde \xb$ es una solución
particular del sistema, el conjunto de todas las soluciones del sistema
es
$$
S = \{\tilde \xb + \vb: \vb \text{ una solución cualquiera del sistema homogéneo } \Ab\xb = 0\}.
$$
\end{proposicion}

\textbf{Idea de la demostración:} si $\xb, \yb$ son soluciones del sistema no
homogéneo, entonces

$$
\Ab\xb - \Ab\yb = \bb - \bb = 0,
$$

Por lo tanto $\zb = \xb-\yb$ es solución del sistema homogéneo y $\xb = \yb + \zb$.

\begin{ejemplo} Resolver el sistema de ecuaciones

$$
\left\{
\begin{aligned}
3x + 2y + 6z &= 12 \\
x - 3y + z &= 10.
\end{aligned}
\right.
$$

En \python podemos calcular una base del núcleo de una matriz con el comando \texttt{null\_space} del paquete \texttt{scipy.linalg}. Para calcular una solución particular usamos eliminación gaussiana.

\begin{Shaded}
\begin{lstlisting}[language=Python]
import scipy.linalg
A = np.array([[3, 2, 6],[1, -2, 1]])
print("Núcleo de A: \n", scipy.linalg.null_space(A))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
Núcleo de A:
 [[-0.85359507]
 [-0.18291323]
 [ 0.48776861]]
\end{verbatim}

\begin{Shaded}
\begin{lstlisting}[language=Python]
b = np.array([12, 10])
Ab = np.c_[A,b]
print("Matriz ampliada escalonada: \n", row_echelon(Ab))
\end{lstlisting}
\end{Shaded}

\begin{verbatim}
%% Matriz ampliada escalonada:
%%  [[ 1.          0.66666667  2.          4.        ]
%%  [ 0.          1.          0.375      -2.25      ]]
\end{verbatim}

Obtenemos las ecuaciones
$$
\left\{
\begin{aligned}
x + 2/3y + 2z &= 4 \\
y + 0.375z &= -2.25,
\end{aligned}
\right.
$$
y tomando $z=1$ obtenemos la solución $(x,y,z) = (3.75, -2.625, 1)$.

Concluimos que el conjunto de soluciones es
$$
S = (3.75, -2.625, 1) + \langle (-0.8535951, -0.1829132,  0.4877686) \rangle.
$$
\end{ejemplo}

